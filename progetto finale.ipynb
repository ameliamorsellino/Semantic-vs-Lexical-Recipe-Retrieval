{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f5b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wordnet...\n",
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "Recipes: 5,000 | Interactions: 23,121\n",
      "Recipes dataset: 5,000 recipes, 12 features\n",
      "Interactions dataset: 23,121 interactions, 5 features\n",
      "\n",
      "Recipe columns: ['name', 'id', 'minutes', 'contributor_id', 'submitted', 'tags', 'nutrition', 'n_steps', 'steps', 'description', 'ingredients', 'n_ingredients']\n",
      "\n",
      "Sample recipe entry:\n",
      "name                                    crab filled crescent snacks\n",
      "id                                                            94947\n",
      "minutes                                                          70\n",
      "contributor_id                                               111448\n",
      "submitted                                                2004-07-03\n",
      "tags              ['time-to-make', 'course', 'main-ingredient', ...\n",
      "nutrition                      [69.2, 3.0, 9.0, 6.0, 5.0, 4.0, 3.0]\n",
      "n_steps                                                          16\n",
      "steps             ['heat over to 375 degrees', 'spray large cook...\n",
      "description               found in a crescent roll recipe magazine.\n",
      "ingredients       ['crabmeat', 'cream cheese', 'green onions', '...\n",
      "n_ingredients                                                     9\n",
      "Name: 59957, dtype: object\n",
      "\n",
      "======================================================================\n",
      "MERGING DATA\n",
      "======================================================================\n",
      "Merged dataset size: 23,121 rows, 16 columns\n",
      "\n",
      "Columns with missing values:\n",
      "  description: 469 (2.03%)\n",
      "  review: 9 (0.04%)\n",
      "\n",
      "======================================================================\n",
      "EXTRACTING NUTRITIONAL DATA\n",
      "======================================================================\n",
      "Nutritional features added:\n",
      "        calories  total_fat      sugar    sodium   protein  saturated_fat  \\\n",
      "count   23121.00   23121.00   23121.00  23121.00  23121.00       23121.00   \n",
      "mean      511.42      35.39     127.29     28.22     34.84          44.38   \n",
      "std      4990.57      66.32    4137.02     93.91     67.86          85.14   \n",
      "min         0.30       0.00       0.00      0.00      0.00           0.00   \n",
      "25%       173.10       8.00      10.00      5.00      6.00           7.00   \n",
      "50%       305.60      20.00      25.00     15.00     19.00          24.00   \n",
      "75%       489.80      39.00      70.00     33.00     53.00          52.00   \n",
      "max    434360.20    1922.00  362729.00   7333.00   3961.00        4209.00   \n",
      "\n",
      "       carbohydrates  \n",
      "count       23121.00  \n",
      "mean           19.16  \n",
      "std           412.21  \n",
      "min             0.00  \n",
      "25%             4.00  \n",
      "50%             8.00  \n",
      "75%            16.00  \n",
      "max         36098.00  \n",
      "\n",
      "======================================================================\n",
      "ANALYZING RECIPE CHARACTERISTICS\n",
      "======================================================================\n",
      "Unique recipes in dataset: 5,000\n",
      "\n",
      "Top 20 most common ingredients:\n",
      "       ingredient  count\n",
      "             salt   1838\n",
      "           butter   1220\n",
      "            sugar   1007\n",
      "            onion    847\n",
      "            water    748\n",
      "             eggs    736\n",
      "        olive oil    729\n",
      "            flour    574\n",
      "             milk    561\n",
      "    garlic cloves    548\n",
      "           pepper    490\n",
      "           garlic    395\n",
      "              egg    387\n",
      "      brown sugar    381\n",
      "all-purpose flour    362\n",
      "    baking powder    359\n",
      "  parmesan cheese    332\n",
      "  salt and pepper    325\n",
      "    vegetable oil    299\n",
      "          vanilla    298\n",
      "\n",
      "Top 30 most common tags:\n",
      "                  tag  frequency\n",
      "          preparation       4981\n",
      "         time-to-make       4864\n",
      "               course       4721\n",
      "      main-ingredient       3668\n",
      "              dietary       3581\n",
      "                 easy       2743\n",
      "             occasion       2443\n",
      "              cuisine       1999\n",
      "     low-in-something       1878\n",
      "            main-dish       1567\n",
      "            equipment       1558\n",
      "   60-minutes-or-less       1467\n",
      "   number-of-servings       1255\n",
      "                 meat       1195\n",
      "   30-minutes-or-less       1149\n",
      "      4-hours-or-less       1130\n",
      "           vegetables       1128\n",
      "           taste-mood       1087\n",
      "       north-american       1044\n",
      "   15-minutes-or-less        986\n",
      "      3-steps-or-less        965\n",
      "           low-sodium        955\n",
      "             desserts        943\n",
      "             low-carb        931\n",
      "              healthy        847\n",
      "          low-calorie        818\n",
      "5-ingredients-or-less        802\n",
      "         dinner-party        792\n",
      "        beginner-cook        785\n",
      "           vegetarian        784\n",
      "\n",
      "Semantic tags present in dataset:\n",
      "  ✓ comfort-food: 552 recipes\n",
      "  ✓ healthy: 847 recipes\n",
      "  ✓ easy: 2,743 recipes\n",
      "  ✓ romantic: 104 recipes\n",
      "  ✓ vegetarian: 784 recipes\n",
      "  ✓ low-carb: 931 recipes\n",
      "  ✓ lunch: 524 recipes\n",
      "  ✓ breakfast: 290 recipes\n",
      "  ✓ italian: 164 recipes\n",
      "  ✓ mexican: 139 recipes\n",
      "  ✓ asian: 297 recipes\n",
      "  ✓ summer: 218 recipes\n",
      "  ✓ winter: 145 recipes\n",
      "\n",
      "======================================================================\n",
      "CREATING SEARCH CORPUS\n",
      "======================================================================\n",
      "  Cleaned: name\n",
      "  Cleaned: tags\n",
      "  Cleaned: description\n",
      "  Cleaned: ingredients\n",
      "  Cleaned: steps\n",
      "\n",
      "Removed 0 recipes with insufficient text\n",
      "Final corpus size: 5,000 recipes\n",
      "\n",
      "======================================================================\n",
      "EXPORTING CORPUS\n",
      "======================================================================\n",
      "Saved corpus to 'search_corpus.csv'\n",
      "Saved metadata to 'recipe_metadata.csv'\n",
      "\n",
      "======================================================================\n",
      "CORPUS QUALITY CHECK\n",
      "======================================================================\n",
      "Checking corpus coverage for potential search queries:\n",
      "\n",
      "  'comfort food': 588 potential matches\n",
      "  'healthy dinner': 159 potential matches\n",
      "  'quick breakfast': 74 potential matches\n",
      "  'romantic dinner': 69 potential matches\n",
      "  'vegetarian lunch': 117 potential matches\n",
      "  'low carb': 969 potential matches\n",
      "  'summer dessert': 67 potential matches\n",
      "  'holiday cookies': 99 potential matches\n",
      "\n",
      "======================================================================\n",
      "LOADING CORPUS FOR SEARCH ENGINES\n",
      "======================================================================\n",
      "Loaded 5,000 recipes\n",
      "Average document length: 176 words\n",
      "\n",
      "======================================================================\n",
      "BUILDING TF-IDF SEARCH ENGINE\n",
      "======================================================================\n",
      "    Fitting TF-IDF model...\n",
      "    Preprocessing documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 5000/5000 [00:03<00:00, 1379.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Computing TF-IDF matrix...\n",
      "\n",
      "    TF-IDF Model Statistics:\n",
      "        Documents: 5,000\n",
      "        Vocabulary size: 31,561\n",
      "        N-gram range: (1, 2)\n",
      "        Matrix shape: (5000, 31561)\n",
      "        Matrix sparsity: 99.57%\n",
      "        Non-zero elements: 681,755\n",
      "    Model saved to tfidf_search_engine.pkl\n",
      "\n",
      "======================================================================\n",
      "TESTING TF-IDF ENGINE\n",
      "======================================================================\n",
      "\n",
      "--- Query Analysis for: 'chocolate cake' ---\n",
      "Processed query: 'chocolate cake'\n",
      "Matched unigrams: ['chocolate', 'cake']\n",
      "Matched n-grams: ['chocolate cake']\n",
      "Unmatched terms: []\n",
      "\n",
      "======================================================================\n",
      "SEARCH RESULTS FOR: 'chocolate cake'\n",
      "======================================================================\n",
      "\n",
      "[1] chocolate  cake\n",
      "    Score: 0.3028\n",
      "    Cooking Time: 35 min | Ingredients: 9 | Steps: 4\n",
      "    Description: this is our family's favorite chocolate cake.  \n",
      "the addition of coffee makes a rich tasting cake. also the oil instead of butter is healthier. i some...\n",
      "\n",
      "[2] rich chocolate kahlua bundt cake\n",
      "    Score: 0.2546\n",
      "    Cooking Time: 55 min | Ingredients: 7 | Steps: 5\n",
      "    Description: i checked the other kahlua cakes, and none were like our ours. so... here's another variation on the quick, cake mix, pudding creation....\n",
      "\n",
      "[3] beetnik chocolate cake\n",
      "    Score: 0.2458\n",
      "    Cooking Time: 40 min | Ingredients: 9 | Steps: 9\n",
      "    Description: there are other chocolate cake recipes here using beets but this one uses cocoa and other ingredients i have at home.  i don't want to lose it but i h...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Query Analysis for: 'pasta carbonara' ---\n",
      "Processed query: 'pasta carbonara'\n",
      "Matched unigrams: ['pasta']\n",
      "Matched n-grams: []\n",
      "Unmatched terms: ['carbonara']\n",
      "\n",
      "======================================================================\n",
      "SEARCH RESULTS FOR: 'pasta carbonara'\n",
      "======================================================================\n",
      "\n",
      "[1] italian vegetable pasta bake\n",
      "    Score: 0.1989\n",
      "    Cooking Time: 0 min | Ingredients: 7 | Steps: 6\n",
      "\n",
      "[2] curly pasta goulash\n",
      "    Score: 0.1802\n",
      "    Cooking Time: 25 min | Ingredients: 6 | Steps: 5\n",
      "    Description: we love this recipe cause it is so easy and quick to make....\n",
      "\n",
      "[3] healthy pasta salad\n",
      "    Score: 0.1709\n",
      "    Cooking Time: 0 min | Ingredients: 6 | Steps: 2\n",
      "    Description: this has become a staple around our house.  ...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Query Analysis for: 'chicken soup' ---\n",
      "Processed query: 'chicken soup'\n",
      "Matched unigrams: ['chicken', 'soup']\n",
      "Matched n-grams: ['chicken soup']\n",
      "Unmatched terms: []\n",
      "\n",
      "======================================================================\n",
      "SEARCH RESULTS FOR: 'chicken soup'\n",
      "======================================================================\n",
      "\n",
      "[1] chicken stuffing with cheese\n",
      "    Score: 0.2834\n",
      "    Cooking Time: 25 min | Ingredients: 5 | Steps: 6\n",
      "    Description: the cook at work (daycare) makes this- it is mine & all the kids' favorite!  i use leftover rotisserie chicken to make it.  never checked the time, so...\n",
      "\n",
      "[2] crock pot chicken and rice  3 ww points\n",
      "    Score: 0.2516\n",
      "    Cooking Time: 365 min | Ingredients: 7 | Steps: 6\n",
      "    Description: from donnita.com...\n",
      "\n",
      "[3] punk s chicken divan\n",
      "    Score: 0.2370\n",
      "    Cooking Time: 45 min | Ingredients: 10 | Steps: 8\n",
      "    Description: mom's chicken divan...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Query Analysis for: 'comfort food for a rainy day' ---\n",
      "Processed query: 'comfort food rainy day'\n",
      "Matched unigrams: ['comfort', 'food', 'rainy', 'day']\n",
      "Matched n-grams: ['comfort food']\n",
      "Unmatched terms: []\n",
      "\n",
      "======================================================================\n",
      "SEARCH RESULTS FOR: 'comfort food for a rainy day'\n",
      "======================================================================\n",
      "\n",
      "[1] macaroni   cheese\n",
      "    Score: 0.1713\n",
      "    Cooking Time: 25 min | Ingredients: 7 | Steps: 5\n",
      "    Description: here's an easy, basic macocheese (as we call it in our house). comfort food all the way. we like it with salad and maybe some steamed broccoli, if we'...\n",
      "\n",
      "[2] cheesy kielbasa with beans\n",
      "    Score: 0.1587\n",
      "    Cooking Time: 80 min | Ingredients: 13 | Steps: 8\n",
      "    Description: wonderful comfort food that is perfect on a cool rainy or winter's day! this makes a large amount which makes it perfect for a larger family, or have ...\n",
      "\n",
      "[3] avgolemono soup\n",
      "    Score: 0.1410\n",
      "    Cooking Time: 20 min | Ingredients: 3 | Steps: 8\n",
      "    Description: this is a greek soup, it's a lemony chicken noodle [or rice] kinda soup. i learned the recipe from my yia-yia [grandmother] when i was younger. it's g...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "TF-IDF ENGINE READY\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "import logging\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "\n",
    "# Data Science & Plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "# Machine Learning & NLP\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# GUI (Tkinter)\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext, messagebox\n",
    "from tkinter import font as tkfont\n",
    "\n",
    "# Configuration & Downloads\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# NLTK Downloads - with check to avoid re-downloading\n",
    "def download_nltk_resources():\n",
    "    \"\"\"Download required NLTK resources if not already present.\"\"\"\n",
    "    resources = [\n",
    "        ('tokenizers/punkt', 'punkt'),\n",
    "        ('corpora/stopwords', 'stopwords'),\n",
    "        ('corpora/wordnet', 'wordnet'),\n",
    "        ('taggers/averaged_perceptron_tagger', 'averaged_perceptron_tagger'),\n",
    "        ('tokenizers/punkt_tab', 'punkt_tab')\n",
    "    ]\n",
    "    \n",
    "    for path, name in resources:\n",
    "        try:\n",
    "            nltk.data.find(path)\n",
    "        except LookupError:\n",
    "            print(f\"Downloading {name}...\")\n",
    "            nltk.download(name, quiet=True)\n",
    "\n",
    "download_nltk_resources()\n",
    "\n",
    "# Test mode\n",
    "TEST_MODE = True       # Set to False for full dataset\n",
    "SAMPLE_SIZE = 5000     # Number of recipes when TEST_MODE is True\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "recipes_df = pd.read_csv(\"RAW_recipes.csv\")\n",
    "interactions_df = pd.read_csv(\"RAW_interactions.csv\")\n",
    "if TEST_MODE:\n",
    "    recipes_df = recipes_df.sample(n=min(SAMPLE_SIZE, len(recipes_df)), random_state=42)\n",
    "    interactions_df = interactions_df[interactions_df['recipe_id'].isin(recipes_df['id'])]\n",
    "print(f\"Recipes: {len(recipes_df):,} | Interactions: {len(interactions_df):,}\")\n",
    "\n",
    "\n",
    "print(f\"Recipes dataset: {recipes_df.shape[0]:,} recipes, {recipes_df.shape[1]} features\")\n",
    "print(f\"Interactions dataset: {interactions_df.shape[0]:,} interactions, {interactions_df.shape[1]} features\")\n",
    "\n",
    "# Preview recipe structure\n",
    "print(\"\\nRecipe columns:\", list(recipes_df.columns))\n",
    "print(\"\\nSample recipe entry:\")\n",
    "print(recipes_df.iloc[0])\n",
    "\n",
    "# =============================================================================\n",
    "# DATA MERGING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MERGING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Join recipes with user interactions\n",
    "merged_data = recipes_df.merge(\n",
    "    interactions_df,\n",
    "    how=\"inner\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"recipe_id\"\n",
    ")\n",
    "\n",
    "# Remove duplicate column after merge\n",
    "if \"recipe_id\" in merged_data.columns:\n",
    "    merged_data = merged_data.drop(columns=[\"recipe_id\"])\n",
    "\n",
    "print(f\"Merged dataset size: {merged_data.shape[0]:,} rows, {merged_data.shape[1]} columns\")\n",
    "\n",
    "# Check for missing data\n",
    "null_summary = merged_data.isnull().sum()\n",
    "null_present = null_summary[null_summary > 0]\n",
    "print(\"\\nColumns with missing values:\")\n",
    "if len(null_present) > 0:\n",
    "    for col, count in null_present.items():\n",
    "        pct = (count / len(merged_data)) * 100\n",
    "        print(f\"  {col}: {count:,} ({pct:.2f}%)\")\n",
    "else:\n",
    "    print(\"  None found\")\n",
    "\n",
    "# =============================================================================\n",
    "# NUTRITIONAL DATA EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXTRACTING NUTRITIONAL DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "nutrition_columns = [\"calories\", \"total_fat\", \"sugar\", \"sodium\", \"protein\", \"saturated_fat\", \"carbohydrates\"]\n",
    "\n",
    "def parse_nutrition_string(nutrition_str: str) -> List[float]:\n",
    "    \"\"\"Extract numerical values from nutrition string.\"\"\"\n",
    "    try:\n",
    "        cleaned = str(nutrition_str).strip(\"[]\")\n",
    "        values = [float(v.strip()) for v in cleaned.split(\",\")]\n",
    "        if len(values) != 7:\n",
    "            logger.warning(f\"Unexpected nutrition values count: {len(values)}\")\n",
    "            return [np.nan] * 7\n",
    "        return values\n",
    "    except (ValueError, AttributeError) as e:\n",
    "        logger.debug(f\"Failed to parse nutrition string: {nutrition_str[:50]}... Error: {e}\")\n",
    "        return [np.nan] * 7\n",
    "\n",
    "# Apply parsing and create new columns\n",
    "nutrition_values = merged_data[\"nutrition\"].apply(parse_nutrition_string)\n",
    "nutrition_df = pd.DataFrame(nutrition_values.tolist(), columns=nutrition_columns, index=merged_data.index)\n",
    "\n",
    "# Merge with dataframe\n",
    "merged_data = pd.concat([merged_data, nutrition_df], axis=1)\n",
    "\n",
    "print(\"Nutritional features added:\")\n",
    "print(merged_data[nutrition_columns].describe().round(2))\n",
    "\n",
    "# =============================================================================\n",
    "# RECIPE CHARACTERISTICS ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYZING RECIPE CHARACTERISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get unique recipes for analysis\n",
    "unique_recipes = merged_data.drop_duplicates(subset=[\"id\"])\n",
    "print(f\"Unique recipes in dataset: {len(unique_recipes):,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# INGREDIENT ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def extract_ingredients_list(ing_string: str) -> List[str]:\n",
    "    \"\"\"Parse ingredient string into list.\"\"\"\n",
    "    try:\n",
    "        cleaned = str(ing_string).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "        ingredients = [i.strip().lower() for i in cleaned.split(\",\") if i.strip()]\n",
    "        return ingredients\n",
    "    except (AttributeError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Extract all ingredients\n",
    "all_ingredients = []\n",
    "for ing_str in unique_recipes[\"ingredients\"]:\n",
    "    all_ingredients.extend(extract_ingredients_list(ing_str))\n",
    "\n",
    "# Count frequency\n",
    "ingredient_counts = Counter(all_ingredients)\n",
    "top_ingredients = pd.DataFrame(\n",
    "    ingredient_counts.most_common(20),\n",
    "    columns=[\"ingredient\", \"count\"]\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 most common ingredients:\")\n",
    "print(top_ingredients.to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# TAG ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def extract_tags_list(tag_string: str) -> List[str]:\n",
    "    \"\"\"Parse tag string into list.\"\"\"\n",
    "    try:\n",
    "        cleaned = str(tag_string).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "        tags = [t.strip().lower() for t in cleaned.split(\",\") if t.strip()]\n",
    "        return tags\n",
    "    except (AttributeError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Extract all tags\n",
    "all_tags = []\n",
    "for tag_str in unique_recipes[\"tags\"]:\n",
    "    all_tags.extend(extract_tags_list(tag_str))\n",
    "\n",
    "# Count frequency\n",
    "tag_counts = Counter(all_tags)\n",
    "top_tags = pd.DataFrame(\n",
    "    tag_counts.most_common(30),\n",
    "    columns=[\"tag\", \"frequency\"]\n",
    ")\n",
    "\n",
    "print(\"\\nTop 30 most common tags:\")\n",
    "print(top_tags.to_string(index=False))\n",
    "\n",
    "# Semantic tags for analysis\n",
    "semantic_tags = [\"comfort-food\", \"healthy\", \"quick\", \"easy\", \"romantic\", \"vegetarian\", \n",
    "                 \"low-carb\", \"dessert\", \"dinner\", \"lunch\", \"breakfast\", \"italian\",\n",
    "                 \"mexican\", \"asian\", \"mediterranean\", \"summer\", \"winter\", \"holiday\"]\n",
    "\n",
    "print(\"\\nSemantic tags present in dataset:\")\n",
    "for tag in semantic_tags:\n",
    "    count = tag_counts.get(tag, 0)\n",
    "    if count > 0:\n",
    "        print(f\"  ✓ {tag}: {count:,} recipes\")\n",
    "\n",
    "# =============================================================================\n",
    "# CORPUS CREATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CREATING SEARCH CORPUS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create corpus dataframe with unique recipes\n",
    "corpus = unique_recipes[[\"id\", \"name\", \"tags\", \"description\", \"ingredients\", \"steps\"]].copy()\n",
    "\n",
    "# Clean each text field\n",
    "text_columns = [\"name\", \"tags\", \"description\", \"ingredients\", \"steps\"]\n",
    "\n",
    "for col in text_columns:\n",
    "    corpus[col + \"_clean\"] = (\n",
    "        corpus[col]\n",
    "        .fillna(\"\")\n",
    "        .astype(str)\n",
    "        .str.replace(\"[\", \"\", regex=False)\n",
    "        .str.replace(\"]\", \"\", regex=False)\n",
    "        .str.replace(\"'\", \"\", regex=False)\n",
    "        .str.replace('\"', \"\", regex=False)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "    print(f\"  Cleaned: {col}\")\n",
    "\n",
    "# Combine all text into single document per recipe\n",
    "corpus[\"document\"] = (\n",
    "    corpus[\"name_clean\"] + \" \" +\n",
    "    corpus[\"tags_clean\"] + \" \" +\n",
    "    corpus[\"description_clean\"] + \" \" +\n",
    "    corpus[\"ingredients_clean\"] + \" \" +\n",
    "    corpus[\"steps_clean\"]\n",
    ")\n",
    "\n",
    "# Final cleaning\n",
    "corpus[\"document\"] = (\n",
    "    corpus[\"document\"]\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Add word count\n",
    "corpus[\"word_count\"] = corpus[\"document\"].str.split().str.len()\n",
    "\n",
    "# Remove recipes with empty documents\n",
    "initial_count = len(corpus)\n",
    "corpus = corpus[corpus[\"document\"].str.len() > 10].copy()\n",
    "print(f\"\\nRemoved {initial_count - len(corpus)} recipes with insufficient text\")\n",
    "print(f\"Final corpus size: {len(corpus):,} recipes\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXPORT CORPUS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPORTING CORPUS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save full corpus with metadata\n",
    "corpus_export = corpus[[\"id\", \"name\", \"tags_clean\", \"document\", \"word_count\"]].copy()\n",
    "corpus_export.columns = [\"recipe_id\", \"recipe_name\", \"tags\", \"document\", \"word_count\"]\n",
    "corpus_export.to_csv(\"search_corpus.csv\", index=False)\n",
    "print(f\"Saved corpus to 'search_corpus.csv'\")\n",
    "\n",
    "# Save recipe metadata\n",
    "metadata = unique_recipes[[\"id\", \"name\", \"minutes\", \"n_ingredients\", \"n_steps\", \"description\"]].copy()\n",
    "metadata.columns = [\"recipe_id\", \"recipe_name\", \"cooking_time\", \"num_ingredients\", \"num_steps\", \"description\"]\n",
    "metadata.to_csv(\"recipe_metadata.csv\", index=False)\n",
    "print(f\"Saved metadata to 'recipe_metadata.csv'\")\n",
    "\n",
    "# =============================================================================\n",
    "# CORPUS QUALITY CHECK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CORPUS QUALITY CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_queries = [\n",
    "    \"comfort food\",\n",
    "    \"healthy dinner\",\n",
    "    \"quick breakfast\",\n",
    "    \"romantic dinner\",\n",
    "    \"vegetarian lunch\",\n",
    "    \"low carb\",\n",
    "    \"summer dessert\",\n",
    "    \"holiday cookies\"\n",
    "]\n",
    "\n",
    "print(\"Checking corpus coverage for potential search queries:\\n\")\n",
    "for query in test_queries:\n",
    "    query_terms = query.lower().split()\n",
    "    mask = pd.Series([True] * len(corpus), index=corpus.index)\n",
    "    for term in query_terms:\n",
    "        mask = mask & corpus[\"document\"].str.contains(term, regex=False)\n",
    "    matches = mask.sum()\n",
    "    print(f\"  '{query}': {matches:,} potential matches\")\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD CORPUS FOR SEARCH ENGINES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LOADING CORPUS FOR SEARCH ENGINES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "corpus_df = pd.read_csv(\"search_corpus.csv\")\n",
    "metadata_df = pd.read_csv(\"recipe_metadata.csv\")\n",
    "\n",
    "print(f\"Loaded {len(corpus_df):,} recipes\")\n",
    "print(f\"Average document length: {corpus_df['word_count'].mean():.0f} words\")\n",
    "\n",
    "# =============================================================================\n",
    "# TEXT PREPROCESSING CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class TextPreprocessor:\n",
    "    \"\"\"\n",
    "    Advanced text preprocessor for recipe documents.\n",
    "    Handles tokenization, stopword removal, and lemmatization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 remove_stopwords: bool = True, \n",
    "                 use_lemmatization: bool = True,\n",
    "                 use_stemming: bool = False,\n",
    "                 min_word_length: int = 2,\n",
    "                 custom_stopwords: Optional[set] = None):\n",
    "        \"\"\"\n",
    "        Initialize preprocessor with configuration options.\n",
    "        \n",
    "        Args:\n",
    "            remove_stopwords: Whether to remove English stopwords\n",
    "            use_lemmatization: Whether to apply lemmatization\n",
    "            use_stemming: Whether to apply stemming (alternative to lemmatization)\n",
    "            min_word_length: Minimum word length to keep\n",
    "            custom_stopwords: Additional domain-specific stopwords\n",
    "        \"\"\"\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.use_lemmatization = use_lemmatization\n",
    "        self.use_stemming = use_stemming\n",
    "        self.min_word_length = min_word_length\n",
    "        \n",
    "        # Initialize NLTK tools\n",
    "        self.lemmatizer = WordNetLemmatizer() if use_lemmatization else None\n",
    "        self.stemmer = PorterStemmer() if use_stemming else None\n",
    "        \n",
    "        # Build stopword set\n",
    "        self.stopwords = set(stopwords.words('english')) if remove_stopwords else set()\n",
    "        \n",
    "        # Add recipe-specific stopwords\n",
    "        recipe_stopwords = {\n",
    "            'cup', 'cups', 'tablespoon', 'tablespoons', 'teaspoon', 'teaspoons',\n",
    "            'tbsp', 'tsp', 'oz', 'ounce', 'ounces', 'pound', 'pounds', 'lb', 'lbs',\n",
    "            'inch', 'inches', 'minute', 'minutes', 'hour', 'hours',\n",
    "            'medium', 'large', 'small', 'fresh', 'chopped', 'minced', 'diced',\n",
    "            'add', 'place', 'put', 'make', 'use', 'take', 'get', 'set',\n",
    "            'recipe', 'recipes', 'ingredient', 'ingredients', 'step', 'steps',\n",
    "            'one', 'two', 'three', 'four', 'five', 'six', 'time', 'preparation',\n",
    "            'optional', 'needed', 'taste', 'degree', 'degrees'\n",
    "        }\n",
    "        self.stopwords.update(recipe_stopwords)\n",
    "        \n",
    "        if custom_stopwords:\n",
    "            self.stopwords.update(custom_stopwords)\n",
    "    \n",
    "    def preprocess(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Full preprocessing pipeline for a single document.\n",
    "        \n",
    "        Args:\n",
    "            text: Raw text string\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text string\n",
    "        \"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        try:\n",
    "            tokens = word_tokenize(text)\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Tokenization failed: {e}\")\n",
    "            tokens = text.split()\n",
    "        \n",
    "        # Process tokens\n",
    "        processed_tokens = []\n",
    "        for token in tokens:\n",
    "            if len(token) < self.min_word_length:\n",
    "                continue\n",
    "            \n",
    "            if self.remove_stopwords and token in self.stopwords:\n",
    "                continue\n",
    "            \n",
    "            if self.use_lemmatization and self.lemmatizer:\n",
    "                token = self.lemmatizer.lemmatize(token, pos='v')\n",
    "                token = self.lemmatizer.lemmatize(token, pos='n')\n",
    "            elif self.use_stemming and self.stemmer:\n",
    "                token = self.stemmer.stem(token)\n",
    "            \n",
    "            processed_tokens.append(token)\n",
    "        \n",
    "        return ' '.join(processed_tokens)\n",
    "    \n",
    "    def preprocess_batch(self, texts: Union[List[str], pd.Series], show_progress: bool = True) -> List[str]:\n",
    "        \"\"\"\n",
    "        Preprocess a batch of documents.\n",
    "        \n",
    "        Args:\n",
    "            texts: Iterable of text strings\n",
    "            show_progress: Whether to show progress updates\n",
    "            \n",
    "        Returns:\n",
    "            List of preprocessed text strings\n",
    "        \"\"\"\n",
    "        # Convert to list to ensure len() works\n",
    "        if isinstance(texts, pd.Series):\n",
    "            texts = texts.tolist()\n",
    "        else:\n",
    "            texts = list(texts)\n",
    "        \n",
    "        processed = []\n",
    "        total = len(texts)\n",
    "        \n",
    "        iterator = tqdm(texts, desc=\"Preprocessing\", disable=not show_progress)\n",
    "        for text in iterator:\n",
    "            processed.append(self.preprocess(text))\n",
    "        \n",
    "        return processed\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TF-IDF SEARCH ENGINE CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class TFIDFSearchEngine:\n",
    "    \"\"\"\n",
    "    TF-IDF based recipe search engine.\n",
    "    Supports both unigrams and n-grams for better phrase matching.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 ngram_range: Tuple[int, int] = (1, 2),\n",
    "                 max_features: int = 50000,\n",
    "                 min_df: int = 2,\n",
    "                 max_df: float = 0.95,\n",
    "                 sublinear_tf: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the TF-IDF search engine.\n",
    "        \"\"\"\n",
    "        self.ngram_range = ngram_range\n",
    "        self.max_features = max_features\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            ngram_range=ngram_range,\n",
    "            max_features=max_features,\n",
    "            min_df=min_df,\n",
    "            max_df=max_df,\n",
    "            sublinear_tf=sublinear_tf,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.preprocessor = TextPreprocessor(\n",
    "            remove_stopwords=True,\n",
    "            use_lemmatization=True,\n",
    "            use_stemming=False\n",
    "        )\n",
    "        \n",
    "        self.tfidf_matrix = None\n",
    "        self.document_ids = None\n",
    "        self.id_to_index: Dict[int, int] = {}  # Fast lookup\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, documents: Union[List[str], pd.Series], \n",
    "            document_ids: Optional[List] = None, \n",
    "            preprocess: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Fit the TF-IDF model on a corpus of documents.\n",
    "        \"\"\"\n",
    "        print(\"    Fitting TF-IDF model...\")\n",
    "        \n",
    "        # Convert to list\n",
    "        if isinstance(documents, pd.Series):\n",
    "            documents = documents.tolist()\n",
    "        else:\n",
    "            documents = list(documents)\n",
    "        \n",
    "        # Store document IDs\n",
    "        if document_ids is not None:\n",
    "            self.document_ids = list(document_ids)\n",
    "        else:\n",
    "            self.document_ids = list(range(len(documents)))\n",
    "        \n",
    "        # Build fast lookup dictionary\n",
    "        self.id_to_index = {doc_id: idx for idx, doc_id in enumerate(self.document_ids)}\n",
    "        \n",
    "        # Preprocess documents\n",
    "        if preprocess:\n",
    "            print(\"    Preprocessing documents...\")\n",
    "            processed_docs = self.preprocessor.preprocess_batch(documents, show_progress=True)\n",
    "        else:\n",
    "            processed_docs = documents\n",
    "        \n",
    "        # Fit and transform TF-IDF\n",
    "        print(\"    Computing TF-IDF matrix...\")\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(processed_docs)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        \n",
    "        # Report statistics\n",
    "        vocab_size = len(self.vectorizer.vocabulary_)\n",
    "        n_docs = self.tfidf_matrix.shape[0]\n",
    "        sparsity = 1.0 - (self.tfidf_matrix.nnz / (n_docs * vocab_size))\n",
    "        \n",
    "        print(f\"\\n    TF-IDF Model Statistics:\")\n",
    "        print(f\"        Documents: {n_docs:,}\")\n",
    "        print(f\"        Vocabulary size: {vocab_size:,}\")\n",
    "        print(f\"        N-gram range: {self.ngram_range}\")\n",
    "        print(f\"        Matrix shape: {self.tfidf_matrix.shape}\")\n",
    "        print(f\"        Matrix sparsity: {sparsity:.2%}\")\n",
    "        print(f\"        Non-zero elements: {self.tfidf_matrix.nnz:,}\")\n",
    "        \n",
    "    def search(self, query: str, top_k: int = 10, preprocess: bool = True) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        Search for recipes matching a query.\n",
    "        \n",
    "        Returns:\n",
    "            List of tuples (document_id, similarity_score)\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        # Validate query\n",
    "        if not query or not query.strip():\n",
    "            logger.warning(\"Empty query provided\")\n",
    "            return []\n",
    "        \n",
    "        # Preprocess query\n",
    "        if preprocess:\n",
    "            processed_query = self.preprocessor.preprocess(query)\n",
    "        else:\n",
    "            processed_query = query\n",
    "        \n",
    "        # Check if query has any valid terms after preprocessing\n",
    "        if not processed_query.strip():\n",
    "            logger.warning(f\"Query '{query}' is empty after preprocessing\")\n",
    "            return []\n",
    "        \n",
    "        # Transform query to TF-IDF vector\n",
    "        query_vector = self.vectorizer.transform([processed_query])\n",
    "        \n",
    "        # Compute cosine similarities\n",
    "        similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        # Get top-k results\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            doc_id = self.document_ids[idx]\n",
    "            score = float(similarities[idx])\n",
    "            if score > 0:  # Only include results with positive similarity\n",
    "                results.append((doc_id, score))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_query_terms(self, query: str, preprocess: bool = True) -> Dict:\n",
    "        \"\"\"Get the terms from a query that exist in the vocabulary.\"\"\"\n",
    "        if preprocess:\n",
    "            processed_query = self.preprocessor.preprocess(query)\n",
    "        else:\n",
    "            processed_query = query\n",
    "        \n",
    "        query_terms = processed_query.split()\n",
    "        vocabulary = set(self.vectorizer.vocabulary_.keys())\n",
    "        \n",
    "        matched = [t for t in query_terms if t in vocabulary]\n",
    "        unmatched = [t for t in query_terms if t not in vocabulary]\n",
    "        \n",
    "        matched_ngrams = []\n",
    "        for n in range(2, self.ngram_range[1] + 1):\n",
    "            for i in range(len(query_terms) - n + 1):\n",
    "                ngram = ' '.join(query_terms[i:i+n])\n",
    "                if ngram in vocabulary:\n",
    "                    matched_ngrams.append(ngram)\n",
    "        \n",
    "        return {\n",
    "            'original_query': query,\n",
    "            'processed_query': processed_query,\n",
    "            'matched_terms': matched,\n",
    "            'matched_ngrams': matched_ngrams,\n",
    "            'unmatched_terms': unmatched\n",
    "        }\n",
    "    \n",
    "    def get_top_terms_for_document(self, doc_id: int, top_k: int = 10) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Get the highest weighted TF-IDF terms for a document.\"\"\"\n",
    "        if doc_id not in self.id_to_index:\n",
    "            raise ValueError(f\"Document ID {doc_id} not found\")\n",
    "        \n",
    "        idx = self.id_to_index[doc_id]\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        doc_vector = self.tfidf_matrix[idx].toarray().flatten()\n",
    "        \n",
    "        top_indices = np.argsort(doc_vector)[::-1][:top_k]\n",
    "        \n",
    "        return [(feature_names[i], float(doc_vector[i])) for i in top_indices if doc_vector[i] > 0]\n",
    "    \n",
    "    def save(self, filepath: str) -> None:\n",
    "        \"\"\"Save the fitted model to disk.\"\"\"\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'vectorizer': self.vectorizer,\n",
    "                'tfidf_matrix': self.tfidf_matrix,\n",
    "                'document_ids': self.document_ids,\n",
    "                'id_to_index': self.id_to_index,\n",
    "                'preprocessor': self.preprocessor,\n",
    "                'ngram_range': self.ngram_range,\n",
    "                'max_features': self.max_features\n",
    "            }, f)\n",
    "        print(f\"    Model saved to {filepath}\")\n",
    "    \n",
    "    def load(self, filepath: str) -> None:\n",
    "        \"\"\"Load a fitted model from disk.\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.vectorizer = data['vectorizer']\n",
    "        self.tfidf_matrix = data['tfidf_matrix']\n",
    "        self.document_ids = data['document_ids']\n",
    "        self.id_to_index = data.get('id_to_index', {doc_id: idx for idx, doc_id in enumerate(self.document_ids)})\n",
    "        self.preprocessor = data['preprocessor']\n",
    "        self.ngram_range = data['ngram_range']\n",
    "        self.max_features = data['max_features']\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        print(f\"    Model loaded from {filepath}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def display_search_results(results: List[Tuple[int, float]], \n",
    "                          metadata_df: pd.DataFrame, \n",
    "                          corpus_df: pd.DataFrame, \n",
    "                          query: str, \n",
    "                          show_snippet: bool = True) -> None:\n",
    "    \"\"\"Display search results in a formatted way.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SEARCH RESULTS FOR: '{query}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    for rank, (recipe_id, score) in enumerate(results, 1):\n",
    "        meta_row = metadata_df[metadata_df['recipe_id'] == recipe_id]\n",
    "        corpus_row = corpus_df[corpus_df['recipe_id'] == recipe_id]\n",
    "        \n",
    "        if len(meta_row) == 0:\n",
    "            continue\n",
    "            \n",
    "        meta = meta_row.iloc[0]\n",
    "        \n",
    "        print(f\"\\n[{rank}] {meta['recipe_name']}\")\n",
    "        print(f\"    Score: {score:.4f}\")\n",
    "        print(f\"    Cooking Time: {meta['cooking_time']} min | \"\n",
    "              f\"Ingredients: {meta['num_ingredients']} | \"\n",
    "              f\"Steps: {meta['num_steps']}\")\n",
    "        \n",
    "        if show_snippet and len(corpus_row) > 0:\n",
    "            doc = corpus_row.iloc[0]['document']\n",
    "            snippet = doc[:200] + \"...\" if len(doc) > 200 else doc\n",
    "            print(f\"    Preview: {snippet}\")\n",
    "        \n",
    "        if pd.notna(meta['description']) and str(meta['description']) != 'nan':\n",
    "            desc = str(meta['description'])[:150]\n",
    "            print(f\"    Description: {desc}...\")\n",
    "\n",
    "\n",
    "def analyze_query_matching(search_engine: TFIDFSearchEngine, query: str) -> None:\n",
    "    \"\"\"Analyze how a query is being matched by the TF-IDF model.\"\"\"\n",
    "    analysis = search_engine.get_query_terms(query)\n",
    "    \n",
    "    print(f\"\\n--- Query Analysis for: '{query}' ---\")\n",
    "    print(f\"Processed query: '{analysis['processed_query']}'\")\n",
    "    print(f\"Matched unigrams: {analysis['matched_terms']}\")\n",
    "    print(f\"Matched n-grams: {analysis['matched_ngrams']}\")\n",
    "    print(f\"Unmatched terms: {analysis['unmatched_terms']}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BUILD TF-IDF SEARCH ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BUILDING TF-IDF SEARCH ENGINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "tfidf_engine = TFIDFSearchEngine(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000,\n",
    "    min_df=3,\n",
    "    max_df=0.90,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "tfidf_engine.fit(\n",
    "    documents=corpus_df['document'],\n",
    "    document_ids=corpus_df['recipe_id'].tolist(),\n",
    "    preprocess=True\n",
    ")\n",
    "\n",
    "tfidf_engine.save(\"tfidf_search_engine.pkl\")\n",
    "\n",
    "# =============================================================================\n",
    "# TEST TF-IDF ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TESTING TF-IDF ENGINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_queries = [\n",
    "    \"chocolate cake\",\n",
    "    \"pasta carbonara\",\n",
    "    \"chicken soup\",\n",
    "    \"comfort food for a rainy day\",\n",
    "    \"healthy dinner after gym\",\n",
    "    \"quick and easy breakfast\",\n",
    "    \"romantic dinner for two\",\n",
    "    \"light summer salad\",\n",
    "]\n",
    "\n",
    "for query in test_queries[:4]:  # Test first 4 queries\n",
    "    analyze_query_matching(tfidf_engine, query)\n",
    "    results = tfidf_engine.search(query, top_k=3)\n",
    "    display_search_results(results, metadata_df, corpus_df, query, show_snippet=False)\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TF-IDF ENGINE READY\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53e69a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 18:53:20,033 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS is available for fast similarity search\n",
      "Using device: cpu\n",
      "\n",
      "======================================================================\n",
      "BUILDING EMBEDDINGS SEARCH ENGINE\n",
      "======================================================================\n",
      "    Loading model: all-MiniLM-L6-v2\n",
      "    Embedding dimension: 384\n",
      "\n",
      "    Computing document embeddings...\n",
      "    Preparing documents from DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing documents: 100%|██████████| 5000/5000 [00:00<00:00, 32789.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Encoding 5,000 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6eb777806d4654b38831f9b5166ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Embeddings shape: (5000, 384)\n",
      "    Building FAISS index...\n",
      "    FAISS index built with 5000 vectors\n",
      "\n",
      "    Embeddings Search Engine Statistics:\n",
      "        Documents: 5,000\n",
      "        Embedding dimension: 384\n",
      "        Total memory: 7.3 MB\n",
      "        Using FAISS: True\n",
      "    Embeddings saved to embeddings_search_engine.pkl\n",
      "\n",
      "======================================================================\n",
      "TESTING EMBEDDINGS ENGINE\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c761990bf34d27bb5608f40ef117b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EMBEDDINGS RESULTS FOR: 'chocolate cake'\n",
      "======================================================================\n",
      "\n",
      "[1] heavenly chocolate cake\n",
      "    Similarity Score: 0.6097\n",
      "    Cooking Time: 50 min | Ingredients: 8 | Steps: 11\n",
      "    Tags: 60-minutes-or-less, time-to-make, course, preparation, occasion, for-large-groups, desserts, oven, e...\n",
      "    Description: this is a sinfully rich cake that would be wonderful for a birthday party. i found it in our local newspaper years ago and have make it numrous times....\n",
      "\n",
      "[2] mimi s double rich chocolate cake  from a cake mix\n",
      "    Similarity Score: 0.5909\n",
      "    Cooking Time: 80 min | Ingredients: 6 | Steps: 9\n",
      "    Tags: time-to-make, course, preparation, desserts, cakes, dietary, 4-hours-or-less...\n",
      "    Description: this is a fantastic cake starting with a cake mix and so easy to do.  i bake it in a angel food pan and it comes out great.  frost it with a butter fr...\n",
      "\n",
      "[3] paradise cake\n",
      "    Similarity Score: 0.5908\n",
      "    Cooking Time: 30 min | Ingredients: 10 | Steps: 15\n",
      "    Tags: 30-minutes-or-less, time-to-make, course, main-ingredient, preparation, occasion, desserts, kosher, ...\n",
      "    Description: this is truly an amazingly delicious dessert. as my husband has been known to say, ...\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91997e3452740e582860f34d40d807d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EMBEDDINGS RESULTS FOR: 'pasta carbonara'\n",
      "======================================================================\n",
      "\n",
      "[1] eggless spaghetti carbonara   california pizza kitchen\n",
      "    Similarity Score: 0.5743\n",
      "    Cooking Time: 15 min | Ingredients: 7 | Steps: 9\n",
      "    Tags: bacon, 15-minutes-or-less, time-to-make, course, main-ingredient, preparation, main-dish, pasta, por...\n",
      "    Description: got this recipe from their cookbook....\n",
      "\n",
      "[2] easy carbonara\n",
      "    Similarity Score: 0.5490\n",
      "    Cooking Time: 30 min | Ingredients: 9 | Steps: 6\n",
      "    Tags: 30-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, occasion, for-1-or-...\n",
      "    Description: my favourite pasta recipe which is easy to prepare, delicious and low in fat!...\n",
      "\n",
      "[3] spaghetti sauce to die for\n",
      "    Similarity Score: 0.4891\n",
      "    Cooking Time: 145 min | Ingredients: 15 | Steps: 13\n",
      "    Tags: weeknight, time-to-make, course, main-ingredient, cuisine, preparation, occasion, healthy, main-dish...\n",
      "    Description: this is a hearty (meaty) yet tangy spaghetti sauce that i have tweaked to almost perfection. a must try for any italian food lovers out there....\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a2cd0afa914dbc8c47e2d653ff71bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EMBEDDINGS RESULTS FOR: 'chicken soup'\n",
      "======================================================================\n",
      "\n",
      "[1] chicken and beef meatball soup\n",
      "    Similarity Score: 0.6574\n",
      "    Cooking Time: 45 min | Ingredients: 7 | Steps: 16\n",
      "    Tags: 60-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, occasion, soups-ste...\n",
      "    Description: this dutch  recipe is my mother's. she was making this in holland from scratch during the war. in 1951 we came to america and she continued making it ...\n",
      "\n",
      "[2] jan s comforting  yummy but naughty chicken wild rice soup\n",
      "    Similarity Score: 0.6026\n",
      "    Cooking Time: 135 min | Ingredients: 9 | Steps: 4\n",
      "    Tags: weeknight, time-to-make, course, main-ingredient, cuisine, preparation, occasion, north-american, so...\n",
      "    Description: this soup is to die for! my friend jan makes it for potlucks and i can never get enough. it is the best, yummiest, soup around. good for those cold wi...\n",
      "\n",
      "[3] savory meatball soup\n",
      "    Similarity Score: 0.5986\n",
      "    Cooking Time: 380 min | Ingredients: 22 | Steps: 5\n",
      "    Tags: occasion, potluck, taste-mood, savory, to-go...\n",
      "    Description: this savory soup is delicious, quick and so easy to make. just throw everything into the crock pot and voile, a very tasty treat.   \n",
      "best of all it u...\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e6bbb9898e4a668e654aa601e98202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EMBEDDINGS RESULTS FOR: 'comfort food for a rainy day'\n",
      "======================================================================\n",
      "\n",
      "[1] napa dave s mexican chicken soup\n",
      "    Similarity Score: 0.4021\n",
      "    Cooking Time: 20 min | Ingredients: 11 | Steps: 7\n",
      "    Tags: 30-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, north-american, hea...\n",
      "    Description: a delightful combination of ingredients and easy to make as well. and if you are feeling under the weather, this will cure what ails you (just ask you...\n",
      "\n",
      "[2] chinese melon soup  dong gwah jong\n",
      "    Similarity Score: 0.3911\n",
      "    Cooking Time: 45 min | Ingredients: 11 | Steps: 7\n",
      "    Tags: 60-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, occasion, north-ame...\n",
      "    Description: great summer soup. it sounds really weird, but it's so good. dh says absolutely not to leave out the watermelon because it really adds to the flavor o...\n",
      "\n",
      "[3] indian chicken with vegetables  murgh subji wala\n",
      "    Similarity Score: 0.3907\n",
      "    Cooking Time: 55 min | Ingredients: 14 | Steps: 13\n",
      "    Tags: curries, 60-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, occasion, ...\n",
      "    Description: i can't go too long without eating indian food. i need it for survival. it's one of my basic food groups! :) have this with some hot chapatis and a fe...\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a3c95ce48c4697894b69c8baa35f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EMBEDDINGS RESULTS FOR: 'healthy dinner after gym'\n",
      "======================================================================\n",
      "\n",
      "[1] marmie s delicious asain flavor  low cal  low fat vegetable soup\n",
      "    Similarity Score: 0.4221\n",
      "    Cooking Time: 45 min | Ingredients: 14 | Steps: 9\n",
      "    Tags: 60-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, occasion, for-large...\n",
      "    Description: amazingly delicious, low calorie, low fat, somewhat spicy, oriental flavor diet soup!  a really nice change from the tomatoe based diet soups.  \n",
      "this...\n",
      "\n",
      "[2] apple pie in a bowl\n",
      "    Similarity Score: 0.4201\n",
      "    Cooking Time: 5 min | Ingredients: 3 | Steps: 3\n",
      "    Tags: 15-minutes-or-less, time-to-make, course, main-ingredient, preparation, for-1-or-2, low-protein, hea...\n",
      "    Description: this is something i like to eat for breakfast on a cold day. i keep the ingredients on hand at work so i can heat this up fresh and start the day off ...\n",
      "\n",
      "[3] sophie s super easy chickie pea and mato salad\n",
      "    Similarity Score: 0.4187\n",
      "    Cooking Time: 15 min | Ingredients: 12 | Steps: 4\n",
      "    Tags: 15-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, low-protein, health...\n",
      "    Description: a refreshing, flavorful salad with just a hint of smokiness.  my 3 year old and i were looking to make a quick and healthy lunch with what we had on h...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "SAVING SEARCH RESULTS FOR COMPARISON\n",
      "======================================================================\n",
      "TF-IDF search results saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f939f8a2904c8fbddb1444e8735e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9fb711e92d4369af2c2340d928434a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55e2727d4bf4bd5ba7fcbe3ee74e3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16682bb7de84e2e94e830f784e31073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707571642d24407da55d2dab8a2be8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2fa3429c8b4003849d02cf3036b06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dc28ac5ddb4291bce8969df86e49dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d645ab1be35a46299ee05e54f13b1e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings search results saved\n",
      "\n",
      "======================================================================\n",
      "EMBEDDING SPACE ANALYSIS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e579d1825114b2f86e107ea751fe86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query-to-Query Similarity Matrix:\n",
      "                      healthy dinner nutritious meal       diet food    comfort food     hearty meal     cozy dinner\n",
      "healthy dinner                 1.000           0.731           0.568           0.536           0.643           0.630\n",
      "nutritious meal                0.731           1.000           0.673           0.554           0.660           0.442\n",
      "diet food                      0.568           0.673           1.000           0.526           0.525           0.291\n",
      "comfort food                   0.536           0.554           0.526           1.000           0.618           0.582\n",
      "hearty meal                    0.643           0.660           0.525           0.618           1.000           0.526\n",
      "cozy dinner                    0.630           0.442           0.291           0.582           0.526           1.000\n",
      "\n",
      "======================================================================\n",
      "SIMILAR RECIPES DEMO\n",
      "======================================================================\n",
      "\n",
      "Finding recipes similar to: 'crab filled crescent snacks' (ID: 94947)\n",
      "\n",
      "Similar recipes:\n",
      "  1. california crab melt (similarity: 0.7528)\n",
      "  2. spinach stuffed crescent rolls (similarity: 0.7468)\n",
      "  3. virginia crab imperial (similarity: 0.7405)\n",
      "  4. green and gold casserole (similarity: 0.7069)\n",
      "  5. creamed crabmeat with artichoke hearts (similarity: 0.6945)\n",
      "\n",
      "======================================================================\n",
      "PREPARING DATA FOR GUI\n",
      "======================================================================\n",
      "Recipe data prepared: 5,000 recipes\n",
      "Columns: ['recipe_id', 'recipe_name', 'cooking_time', 'num_ingredients', 'num_steps', 'description', 'tags']\n",
      "\n",
      "======================================================================\n",
      "EMBEDDINGS ENGINE COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FAISS AVAILABILITY CHECK\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    FAISS_AVAILABLE = True\n",
    "    print(\"FAISS is available for fast similarity search\")\n",
    "except ImportError:\n",
    "    FAISS_AVAILABLE = False\n",
    "    print(\"Note: FAISS not installed. Using sklearn for similarity search.\")\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DOCUMENT PREPARER CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class DocumentPreparer:\n",
    "    \"\"\"\n",
    "    Prepares recipe documents for embedding.\n",
    "    Different from TF-IDF preprocessing - preserves semantic meaning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_length: int = 512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_length: Maximum document length (in words) to prevent \n",
    "                       truncation issues with transformer models\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def prepare_document(self, row: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Create an optimized document representation for embedding.\n",
    "        \n",
    "        Args:\n",
    "            row: DataFrame row with recipe data\n",
    "            \n",
    "        Returns:\n",
    "            Formatted document string\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # Recipe name (most important)\n",
    "        recipe_name = row.get('recipe_name', '')\n",
    "        if pd.notna(recipe_name) and str(recipe_name).strip():\n",
    "            name = str(recipe_name).strip()\n",
    "            parts.append(f\"Recipe: {name}\")\n",
    "        \n",
    "        # Tags (crucial for semantic matching)\n",
    "        tags = row.get('tags', '')\n",
    "        if pd.notna(tags) and str(tags).strip():\n",
    "            tags_clean = str(tags).strip().replace(',', ', ')\n",
    "            parts.append(f\"Tags: {tags_clean}\")\n",
    "        \n",
    "        # Full document content\n",
    "        document = row.get('document', '')\n",
    "        if pd.notna(document) and str(document).strip():\n",
    "            doc = str(document).strip()\n",
    "            words = doc.split()\n",
    "            if len(words) > self.max_length:\n",
    "                doc = ' '.join(words[:self.max_length])\n",
    "            parts.append(doc)\n",
    "        \n",
    "        return ' '.join(parts)\n",
    "    \n",
    "    def prepare_batch(self, df: pd.DataFrame, show_progress: bool = True) -> List[str]:\n",
    "        \"\"\"\n",
    "        Prepare a batch of documents.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with recipe data\n",
    "            show_progress: Whether to show progress bar\n",
    "            \n",
    "        Returns:\n",
    "            List of prepared document strings\n",
    "        \"\"\"\n",
    "        prepared = []\n",
    "        iterator = tqdm(df.iterrows(), total=len(df), desc=\"Preparing documents\", disable=not show_progress)\n",
    "        \n",
    "        for idx, row in iterator:\n",
    "            prepared.append(self.prepare_document(row))\n",
    "        \n",
    "        return prepared\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EMBEDDINGS SEARCH ENGINE CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class EmbeddingsSearchEngine:\n",
    "    \"\"\"\n",
    "    Neural embeddings-based recipe search engine using Sentence Transformers.\n",
    "    Captures semantic meaning of queries and documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Available models (from smaller/faster to larger/better)\n",
    "    AVAILABLE_MODELS = {\n",
    "        'mini': 'all-MiniLM-L6-v2',           # 80MB, fast, good quality\n",
    "        'mpnet': 'all-mpnet-base-v2',          # 420MB, best quality\n",
    "        'distilbert': 'all-distilroberta-v1',  # 290MB, good balance\n",
    "        'minilm-l12': 'all-MiniLM-L12-v2',     # 120MB, better than L6\n",
    "        'multi': 'paraphrase-multilingual-MiniLM-L12-v2'  # Multilingual\n",
    "    }\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_name: str = 'mini', \n",
    "                 use_faiss: bool = True, \n",
    "                 batch_size: int = 64):\n",
    "        \"\"\"\n",
    "        Initialize the embeddings search engine.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Key from AVAILABLE_MODELS or full HuggingFace model name\n",
    "            use_faiss: Whether to use FAISS for fast similarity search\n",
    "            batch_size: Batch size for encoding documents\n",
    "        \"\"\"\n",
    "        # Resolve model name\n",
    "        if model_name in self.AVAILABLE_MODELS:\n",
    "            self.model_path = self.AVAILABLE_MODELS[model_name]\n",
    "        else:\n",
    "            self.model_path = model_name\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.use_faiss = use_faiss and FAISS_AVAILABLE\n",
    "        \n",
    "        # Load the sentence transformer model\n",
    "        print(f\"    Loading model: {self.model_path}\")\n",
    "        self.model = SentenceTransformer(self.model_path, device=device)\n",
    "        \n",
    "        # Get embedding dimension\n",
    "        self.embedding_dim = self.model.get_sentence_embedding_dimension()\n",
    "        print(f\"    Embedding dimension: {self.embedding_dim}\")\n",
    "        \n",
    "        # Storage\n",
    "        self.embeddings: Optional[np.ndarray] = None\n",
    "        self.document_ids: Optional[List] = None\n",
    "        self.id_to_index: Dict[int, int] = {}  # Fast O(1) lookup\n",
    "        self.faiss_index = None\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # Document preparer\n",
    "        self.doc_preparer = DocumentPreparer(max_length=256)\n",
    "    \n",
    "    def fit(self, \n",
    "            documents: Union[pd.DataFrame, List[str]], \n",
    "            document_ids: Optional[List] = None, \n",
    "            show_progress: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Compute embeddings for all documents in the corpus.\n",
    "        \n",
    "        Args:\n",
    "            documents: List/Series of document strings or DataFrame with recipe data\n",
    "            document_ids: Optional list of document identifiers\n",
    "            show_progress: Whether to show progress bar\n",
    "        \"\"\"\n",
    "        print(\"\\n    Computing document embeddings...\")\n",
    "        \n",
    "        # Handle DataFrame input\n",
    "        if isinstance(documents, pd.DataFrame):\n",
    "            print(\"    Preparing documents from DataFrame...\")\n",
    "            doc_list = self.doc_preparer.prepare_batch(documents, show_progress=show_progress)\n",
    "            if document_ids is None and 'recipe_id' in documents.columns:\n",
    "                document_ids = documents['recipe_id'].tolist()\n",
    "        elif isinstance(documents, pd.Series):\n",
    "            doc_list = documents.tolist()\n",
    "        else:\n",
    "            doc_list = list(documents)\n",
    "        \n",
    "        # Store document IDs\n",
    "        if document_ids is not None:\n",
    "            self.document_ids = list(document_ids)\n",
    "        else:\n",
    "            self.document_ids = list(range(len(doc_list)))\n",
    "        \n",
    "        # Build fast lookup dictionary - O(1) instead of O(n)\n",
    "        self.id_to_index = {doc_id: idx for idx, doc_id in enumerate(self.document_ids)}\n",
    "        \n",
    "        # Compute embeddings in batches\n",
    "        print(f\"    Encoding {len(doc_list):,} documents...\")\n",
    "        self.embeddings = self.model.encode(\n",
    "            doc_list,\n",
    "            batch_size=self.batch_size,\n",
    "            show_progress_bar=show_progress,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True  # L2 normalize for cosine similarity\n",
    "        )\n",
    "        \n",
    "        print(f\"    Embeddings shape: {self.embeddings.shape}\")\n",
    "        \n",
    "        # Build FAISS index for fast search\n",
    "        if self.use_faiss:\n",
    "            self._build_faiss_index()\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        \n",
    "        # Report statistics\n",
    "        print(f\"\\n    Embeddings Search Engine Statistics:\")\n",
    "        print(f\"        Documents: {len(self.document_ids):,}\")\n",
    "        print(f\"        Embedding dimension: {self.embedding_dim}\")\n",
    "        print(f\"        Total memory: {self.embeddings.nbytes / 1024**2:.1f} MB\")\n",
    "        print(f\"        Using FAISS: {self.use_faiss}\")\n",
    "    \n",
    "    def _build_faiss_index(self) -> None:\n",
    "        \"\"\"Build FAISS index for fast approximate nearest neighbor search.\"\"\"\n",
    "        print(\"    Building FAISS index...\")\n",
    "        \n",
    "        # Use Inner Product index (equivalent to cosine similarity for normalized vectors)\n",
    "        self.faiss_index = faiss.IndexFlatIP(self.embedding_dim)\n",
    "        \n",
    "        # Add vectors to index\n",
    "        self.faiss_index.add(self.embeddings.astype(np.float32))\n",
    "        \n",
    "        print(f\"    FAISS index built with {self.faiss_index.ntotal} vectors\")\n",
    "    \n",
    "    def encode_query(self, query: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encode a query string into an embedding vector.\n",
    "        \n",
    "        Args:\n",
    "            query: Query string\n",
    "            \n",
    "        Returns:\n",
    "            Normalized embedding vector\n",
    "        \"\"\"\n",
    "        embedding = self.model.encode(\n",
    "            query,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        return embedding\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        Search for recipes matching a query using semantic similarity.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query string\n",
    "            top_k: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples (document_id, similarity_score)\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        # Validate query\n",
    "        if not query or not query.strip():\n",
    "            logger.warning(\"Empty query provided\")\n",
    "            return []\n",
    "        \n",
    "        # Encode query\n",
    "        query_embedding = self.encode_query(query)\n",
    "        \n",
    "        if self.use_faiss:\n",
    "            # FAISS search\n",
    "            query_embedding = query_embedding.reshape(1, -1).astype(np.float32)\n",
    "            scores, indices = self.faiss_index.search(query_embedding, top_k)\n",
    "            \n",
    "            results = []\n",
    "            for idx, score in zip(indices[0], scores[0]):\n",
    "                if idx != -1:  # FAISS returns -1 for empty results\n",
    "                    doc_id = self.document_ids[idx]\n",
    "                    results.append((doc_id, float(score)))\n",
    "        else:\n",
    "            # Sklearn cosine similarity\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "            similarities = cosine_similarity(query_embedding, self.embeddings).flatten()\n",
    "            \n",
    "            # Get top-k results\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "            \n",
    "            results = []\n",
    "            for idx in top_indices:\n",
    "                doc_id = self.document_ids[idx]\n",
    "                score = float(similarities[idx])\n",
    "                results.append((doc_id, score))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def search_batch(self, queries: List[str], top_k: int = 10) -> Dict[str, List[Tuple[int, float]]]:\n",
    "        \"\"\"\n",
    "        Search for multiple queries at once (more efficient).\n",
    "        \n",
    "        Args:\n",
    "            queries: List of query strings\n",
    "            top_k: Number of results per query\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping queries to their results\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        # Filter empty queries\n",
    "        valid_queries = [q for q in queries if q and q.strip()]\n",
    "        if not valid_queries:\n",
    "            return {q: [] for q in queries}\n",
    "        \n",
    "        # Encode all queries\n",
    "        query_embeddings = self.model.encode(\n",
    "            valid_queries,\n",
    "            batch_size=self.batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        if self.use_faiss:\n",
    "            scores, indices = self.faiss_index.search(\n",
    "                query_embeddings.astype(np.float32), top_k\n",
    "            )\n",
    "            \n",
    "            for i, query in enumerate(valid_queries):\n",
    "                query_results = []\n",
    "                for idx, score in zip(indices[i], scores[i]):\n",
    "                    if idx != -1:\n",
    "                        doc_id = self.document_ids[idx]\n",
    "                        query_results.append((doc_id, float(score)))\n",
    "                results[query] = query_results\n",
    "        else:\n",
    "            similarities = cosine_similarity(query_embeddings, self.embeddings)\n",
    "            \n",
    "            for i, query in enumerate(valid_queries):\n",
    "                top_indices = np.argsort(similarities[i])[::-1][:top_k]\n",
    "                query_results = [\n",
    "                    (self.document_ids[idx], float(similarities[i][idx]))\n",
    "                    for idx in top_indices\n",
    "                ]\n",
    "                results[query] = query_results\n",
    "        \n",
    "        # Add empty results for invalid queries\n",
    "        for query in queries:\n",
    "            if query not in results:\n",
    "                results[query] = []\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_similar_recipes(self, recipe_id: int, top_k: int = 10) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        Find recipes similar to a given recipe.\n",
    "        \n",
    "        Args:\n",
    "            recipe_id: ID of the recipe to find similar items for\n",
    "            top_k: Number of similar recipes to return\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples (recipe_id, similarity_score)\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        # Use O(1) lookup instead of O(n)\n",
    "        if recipe_id not in self.id_to_index:\n",
    "            raise ValueError(f\"Recipe ID {recipe_id} not found in index\")\n",
    "        \n",
    "        idx = self.id_to_index[recipe_id]\n",
    "        recipe_embedding = self.embeddings[idx].reshape(1, -1)\n",
    "        \n",
    "        if self.use_faiss:\n",
    "            scores, indices = self.faiss_index.search(\n",
    "                recipe_embedding.astype(np.float32), top_k + 1\n",
    "            )\n",
    "            # Skip the first result (the recipe itself)\n",
    "            results = []\n",
    "            for i, s in zip(indices[0], scores[0]):\n",
    "                if i != -1 and i != idx:  # Skip self\n",
    "                    results.append((self.document_ids[i], float(s)))\n",
    "            results = results[:top_k]\n",
    "        else:\n",
    "            similarities = cosine_similarity(recipe_embedding, self.embeddings).flatten()\n",
    "            # Set self-similarity to -1 to exclude it\n",
    "            similarities[idx] = -1\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "            results = [\n",
    "                (self.document_ids[i], float(similarities[i]))\n",
    "                for i in top_indices\n",
    "            ]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def compute_query_document_similarity(self, query: str, recipe_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Compute similarity between a query and a specific recipe.\n",
    "        \n",
    "        Args:\n",
    "            query: Query string\n",
    "            recipe_id: ID of the recipe\n",
    "            \n",
    "        Returns:\n",
    "            Similarity score\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        if not query or not query.strip():\n",
    "            return 0.0\n",
    "        \n",
    "        # Use O(1) lookup\n",
    "        if recipe_id not in self.id_to_index:\n",
    "            raise ValueError(f\"Recipe ID {recipe_id} not found in index\")\n",
    "        \n",
    "        query_embedding = self.encode_query(query).reshape(1, -1)\n",
    "        \n",
    "        idx = self.id_to_index[recipe_id]\n",
    "        doc_embedding = self.embeddings[idx].reshape(1, -1)\n",
    "        \n",
    "        similarity = cosine_similarity(query_embedding, doc_embedding)[0][0]\n",
    "        return float(similarity)\n",
    "    \n",
    "    def get_embedding(self, recipe_id: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the embedding vector for a specific recipe.\n",
    "        \n",
    "        Args:\n",
    "            recipe_id: ID of the recipe\n",
    "            \n",
    "        Returns:\n",
    "            Embedding vector\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        if recipe_id not in self.id_to_index:\n",
    "            raise ValueError(f\"Recipe ID {recipe_id} not found in index\")\n",
    "        \n",
    "        idx = self.id_to_index[recipe_id]\n",
    "        return self.embeddings[idx].copy()\n",
    "    \n",
    "    def save(self, filepath: str) -> None:\n",
    "        \"\"\"Save the fitted model data to disk (not the transformer model itself).\"\"\"\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'embeddings': self.embeddings,\n",
    "                'document_ids': self.document_ids,\n",
    "                'id_to_index': self.id_to_index,\n",
    "                'model_path': self.model_path,\n",
    "                'embedding_dim': self.embedding_dim,\n",
    "                'use_faiss': self.use_faiss\n",
    "            }, f)\n",
    "        print(f\"    Embeddings saved to {filepath}\")\n",
    "    \n",
    "    def load(self, filepath: str) -> None:\n",
    "        \"\"\"Load embeddings from disk.\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Check for model mismatch\n",
    "        saved_model_path = data.get('model_path')\n",
    "        if saved_model_path and saved_model_path != self.model_path:\n",
    "            raise ValueError(\n",
    "                f\"Model mismatch: embeddings were created with '{saved_model_path}' \"\n",
    "                f\"but current engine uses '{self.model_path}'. \"\n",
    "                f\"Initialize the engine with model_name='{saved_model_path}' or recompute embeddings.\"\n",
    "            )\n",
    "        \n",
    "        self.embeddings = data['embeddings']\n",
    "        self.document_ids = data['document_ids']\n",
    "        self.id_to_index = data.get('id_to_index', {doc_id: idx for idx, doc_id in enumerate(self.document_ids)})\n",
    "        self.embedding_dim = data['embedding_dim']\n",
    "        \n",
    "        # Restore use_faiss from saved state, but still check FAISS availability\n",
    "        saved_use_faiss = data.get('use_faiss', True)\n",
    "        self.use_faiss = saved_use_faiss and FAISS_AVAILABLE\n",
    "        \n",
    "        # Rebuild FAISS index if needed\n",
    "        if self.use_faiss:\n",
    "            self._build_faiss_index()\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        print(f\"    Embeddings loaded from {filepath}\")\n",
    "\n",
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS FOR EMBEDDINGS RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "def display_search_results_embeddings(results: List[Tuple[int, float]], \n",
    "                                      metadata_df: pd.DataFrame, \n",
    "                                      corpus_df: pd.DataFrame, \n",
    "                                      query: str, \n",
    "                                      engine_name: str = \"EMBEDDINGS\") -> None:\n",
    "    \"\"\"Display search results in a formatted way.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{engine_name} RESULTS FOR: '{query}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    for rank, (recipe_id, score) in enumerate(results, 1):\n",
    "        meta_row = metadata_df[metadata_df['recipe_id'] == recipe_id]\n",
    "        \n",
    "        if len(meta_row) == 0:\n",
    "            continue\n",
    "            \n",
    "        meta = meta_row.iloc[0]\n",
    "        \n",
    "        print(f\"\\n[{rank}] {meta['recipe_name']}\")\n",
    "        print(f\"    Similarity Score: {score:.4f}\")\n",
    "        print(f\"    Cooking Time: {meta['cooking_time']} min | \"\n",
    "              f\"Ingredients: {meta['num_ingredients']} | \"\n",
    "              f\"Steps: {meta['num_steps']}\")\n",
    "        \n",
    "        # Show tags if available\n",
    "        corpus_row = corpus_df[corpus_df['recipe_id'] == recipe_id]\n",
    "        if len(corpus_row) > 0:\n",
    "            tags = corpus_row.iloc[0].get('tags', '')\n",
    "            if pd.notna(tags) and str(tags) != 'nan':\n",
    "                tags_preview = str(tags)[:100]\n",
    "                print(f\"    Tags: {tags_preview}...\")\n",
    "        \n",
    "        # Show description\n",
    "        if pd.notna(meta['description']) and str(meta['description']) != 'nan':\n",
    "            desc = str(meta['description'])[:150]\n",
    "            print(f\"    Description: {desc}...\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BUILD EMBEDDINGS SEARCH ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BUILDING EMBEDDINGS SEARCH ENGINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "embeddings_engine = EmbeddingsSearchEngine(\n",
    "    model_name='mini',  # all-MiniLM-L6-v2\n",
    "    use_faiss=FAISS_AVAILABLE,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "embeddings_engine.fit(\n",
    "    documents=corpus_df,\n",
    "    document_ids=corpus_df['recipe_id'].tolist(),\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "embeddings_engine.save(\"embeddings_search_engine.pkl\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TEST EMBEDDINGS ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TESTING EMBEDDINGS ENGINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_queries_embeddings = [\n",
    "    # Simple keyword queries\n",
    "    \"chocolate cake\",\n",
    "    \"pasta carbonara\",\n",
    "    \"chicken soup\",\n",
    "    \n",
    "    # Semantic/high-level queries\n",
    "    \"comfort food for a rainy day\",\n",
    "    \"healthy dinner after gym\",\n",
    "    \"quick and easy breakfast\",\n",
    "    \"romantic dinner for two\",\n",
    "    \"light summer salad\",\n",
    "    \"warm winter soup\",\n",
    "    \"kid friendly lunch\",\n",
    "    \"low carb vegetarian\",\n",
    "    \n",
    "    # Abstract/mood-based queries\n",
    "    \"something sweet and indulgent\",\n",
    "    \"meal prep for the week\",\n",
    "    \"impressive dish for guests\",\n",
    "    \"nostalgic childhood favorite\"\n",
    "]\n",
    "\n",
    "# Test first few queries\n",
    "for query in test_queries_embeddings[:5]:\n",
    "    results = embeddings_engine.search(query, top_k=3)\n",
    "    display_search_results_embeddings(results, metadata_df, corpus_df, query)\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS FOR COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING SEARCH RESULTS FOR COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_queries = [\n",
    "    \"comfort food for a rainy day\",\n",
    "    \"healthy dinner after gym\",\n",
    "    \"quick and easy breakfast\",\n",
    "    \"romantic dinner for two\",\n",
    "    \"light summer salad\",\n",
    "    \"vegetarian protein rich\",\n",
    "    \"decadent chocolate dessert\",\n",
    "    \"mediterranean diet lunch\"\n",
    "]\n",
    "\n",
    "# Get TF-IDF results\n",
    "tfidf_results = {}\n",
    "for query in comparison_queries:\n",
    "    results = tfidf_engine.search(query, top_k=20)\n",
    "    tfidf_results[query] = results\n",
    "\n",
    "with open(\"tfidf_search_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_results, f)\n",
    "print(\"TF-IDF search results saved\")\n",
    "\n",
    "# Get Embeddings results\n",
    "embeddings_results = {}\n",
    "for query in comparison_queries:\n",
    "    results = embeddings_engine.search(query, top_k=20)\n",
    "    embeddings_results[query] = results\n",
    "\n",
    "with open(\"embeddings_search_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_results, f)\n",
    "print(\"Embeddings search results saved\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EMBEDDING SPACE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EMBEDDING SPACE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "analysis_queries = [\n",
    "    \"healthy dinner\",\n",
    "    \"nutritious meal\",\n",
    "    \"diet food\",\n",
    "    \"comfort food\",\n",
    "    \"hearty meal\",\n",
    "    \"cozy dinner\"\n",
    "]\n",
    "\n",
    "# Encode queries\n",
    "query_embeddings = embeddings_engine.model.encode(\n",
    "    analysis_queries,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "# Compute pairwise similarities\n",
    "query_similarities = cosine_similarity(query_embeddings)\n",
    "\n",
    "print(\"\\nQuery-to-Query Similarity Matrix:\")\n",
    "print(f\"{'':20}\", end=\"\")\n",
    "for q in analysis_queries:\n",
    "    print(f\"{q[:15]:>16}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, q1 in enumerate(analysis_queries):\n",
    "    print(f\"{q1[:20]:20}\", end=\"\")\n",
    "    for j, q2 in enumerate(analysis_queries):\n",
    "        print(f\"{query_similarities[i][j]:16.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FIND SIMILAR RECIPES DEMO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SIMILAR RECIPES DEMO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "sample_recipe_id = corpus_df.iloc[0]['recipe_id']\n",
    "sample_meta = metadata_df[metadata_df['recipe_id'] == sample_recipe_id]\n",
    "\n",
    "if len(sample_meta) > 0:\n",
    "    sample_recipe_name = sample_meta.iloc[0]['recipe_name']\n",
    "    print(f\"\\nFinding recipes similar to: '{sample_recipe_name}' (ID: {sample_recipe_id})\")\n",
    "    \n",
    "    similar_recipes = embeddings_engine.get_similar_recipes(sample_recipe_id, top_k=5)\n",
    "    \n",
    "    print(\"\\nSimilar recipes:\")\n",
    "    for rank, (recipe_id, score) in enumerate(similar_recipes, 1):\n",
    "        meta_row = metadata_df[metadata_df['recipe_id'] == recipe_id]\n",
    "        if len(meta_row) > 0:\n",
    "            name = meta_row.iloc[0]['recipe_name']\n",
    "            print(f\"  {rank}. {name} (similarity: {score:.4f})\")\n",
    "else:\n",
    "    print(\"Could not find sample recipe for demo\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PREPARE RECIPE DATA FOR GUI\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREPARING DATA FOR GUI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "recipe_data = metadata_df.copy()\n",
    "\n",
    "# Add tags from corpus to metadata\n",
    "recipe_data = recipe_data.merge(\n",
    "    corpus_df[['recipe_id', 'tags']], \n",
    "    on='recipe_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Validate merge\n",
    "if len(recipe_data) == 0:\n",
    "    raise ValueError(\"Recipe data merge failed - no records found\")\n",
    "\n",
    "print(f\"Recipe data prepared: {len(recipe_data):,} recipes\")\n",
    "print(f\"Columns: {list(recipe_data.columns)}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EMBEDDINGS ENGINE COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee847241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUATION SYSTEM\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Initializing proxy relevance generator...\n",
      "    Initialized relevance generator with 5000 recipes\n",
      "\n",
      "Evaluating 28 queries...\n",
      "\n",
      "======================================================================\n",
      "ENGINE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "    Evaluating TF-IDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    TF-IDF: 100%|██████████| 28/28 [00:00<00:00, 40.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Evaluating Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd76a117eecd4b98899efa835967b32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aeaaf046674138ab09279c04548d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:   7%|▋         | 2/28 [00:00<00:01, 15.55it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ebf4bb3de84e198eb30392b873a56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4169ed9fa75f494c90da491d63658c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  14%|█▍        | 4/28 [00:00<00:01, 12.43it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf60cdb864f4f9f9eaf6c72693895eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27eb2ba291ad44ffab0aef7d77f77013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  21%|██▏       | 6/28 [00:00<00:01, 12.62it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee2f8377e964d7dbe15afab93e792f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ef2e1d5a8d4e7b8dd10832ab29e3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  29%|██▊       | 8/28 [00:00<00:01, 14.75it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcdd6a9572e4490abf336fd38b6a98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae201be614f4665973aca2074c83f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  36%|███▌      | 10/28 [00:00<00:01, 12.69it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d68bd0041046a8967b0beec5dd1cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f2a8f0b196444f8ce203e9498f5aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  43%|████▎     | 12/28 [00:00<00:01, 11.58it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c4cce8c54c4c589245b2c5f2dc8ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7582b7ca950846a7905b6848bdbd279b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5f567cc38c46c78e83eb16356b28d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  54%|█████▎    | 15/28 [00:01<00:00, 14.72it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866ec90724d943dc86a318bffa0c0725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87236d37da6411ea34c96d539aa28a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  61%|██████    | 17/28 [00:01<00:00, 14.00it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613f6bb5e88d446b90084dee2ee82926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88967457cb34bc6a67e1d41eb434f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  68%|██████▊   | 19/28 [00:01<00:00, 12.40it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc42381070e4941981652adfd1a9a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f8b63eaa7049fa91773fabb8aa6ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  75%|███████▌  | 21/28 [00:01<00:00, 13.51it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5534b3d8de45aca6100556cc381bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad33a37666a44b1484b54492f0f3242f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  82%|████████▏ | 23/28 [00:01<00:00, 14.44it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22494c08e954b9fa7ea22f565493b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1f5876c01e499cbc57bca8a1ad892a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  89%|████████▉ | 25/28 [00:01<00:00, 12.74it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fbf0248eee40d59d55f3fda7d7d057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2188aeb2d6b445abb0e509e10e85c143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings:  96%|█████████▋| 27/28 [00:02<00:00, 13.64it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1ba46e76004cfb9c84b3dc62702d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Embeddings: 100%|██████████| 28/28 [00:02<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    TF-IDF results shape: (28, 18)\n",
      "    Embeddings results shape: (28, 18)\n",
      "\n",
      "    Running statistical tests...\n",
      "\n",
      "    Computing overlap analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10273b6d2ed5479cbbeb7e16d75fa568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61c6f4039ba48afb033d23885be0e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de734d81631447d7b853553f522214f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7153a84b7c44d5faeed1f4d36f10bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3e067269a3403e9b04cd1d4fe82dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36549112cb364d1c8de1b26c2b0c1038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3b34f5938d45eb8370bdc24b334ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23c8bdcbf744967af44f9363a3e2d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23dc5ae643742f98102ee8e592d3810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3065817c21e742819bcc08a105f99bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd38e40f63e469089b5e69905476d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a6bcb6477f4ec2b51b3154cfa4895a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4dc6eede6d4ed695731135bf322ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931c98d700294a9ba5c7f1c9864206b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25f2d15356d41f5b7ec7c4f7ce1b884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb50dbaba1ae482299736261f5763afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad773bd9c9dd42489e5eba13ced4f950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9453e846426c481083e66c18e5cc680d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7163a82ac0045cdaaed123790d9fb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ec3ff7d0ef49e0b954705fcc7cd58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9805c511be7d4c3ca0bdfd214d2f54d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9657381ede49aca63726ab96fa0dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996c662f243649f28d17f5a93411cca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9135d7fd43ac47ef83d32253a66d1370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d629669b94ee4967b1357475256e918f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fec482d0ab498ab0e9d7d00cb4ef9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ff67997e6548ebb29c0e27b8b060b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89715d456d6044bd9e135c088472f150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARISON REPORT\n",
      "======================================================================\n",
      "\n",
      "Engines: TF-IDF vs Embeddings\n",
      "Number of queries: 28\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SUMMARY STATISTICS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Metric                                  TF-IDF           Embeddings       Winner\n",
      "-----------------------------------------------------------------------------\n",
      "precision@10                            0.9250               0.7893       TF-IDF\n",
      "recall@10                               0.1616               0.1338       TF-IDF\n",
      "ndcg@10                                 0.8523               0.7255       TF-IDF\n",
      "reciprocal_rank                         0.9821               0.8158       TF-IDF\n",
      "average_precision                       0.2920               0.2296       TF-IDF\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "STATISTICAL SIGNIFICANCE (p-value < 0.05 is significant)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Metric                       t-test p-val  Wilcoxon p-val    Significant?\n",
      "----------------------------------------------------------------------\n",
      "precision@10                       0.0049          0.0046             Yes\n",
      "recall@10                          0.0070          0.0074             Yes\n",
      "ndcg@10                            0.0078          0.0288             Yes\n",
      "reciprocal_rank                    0.0041          0.0107             Yes\n",
      "average_precision                  0.0013          0.0013             Yes\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "WIN/LOSS ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Metric                        TF-IDF Wins Embeddings Wins       Ties\n",
      "-----------------------------------------------------------------\n",
      "precision@10                           12               3         13\n",
      "recall@10                              18               7          3\n",
      "ndcg@10                                17              10          1\n",
      "reciprocal_rank                         8               0         20\n",
      "average_precision                      22               5          1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "OVERLAP ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Mean Jaccard Similarity: 0.1573\n",
      "Mean Overlap Count (top-20): 4.9\n",
      "Mean Spearman Rank Correlation: 0.2929\n",
      "Mean Kendall Rank Correlation: 0.2333\n",
      "\n",
      "======================================================================\n",
      "END OF COMPARISON REPORT\n",
      "======================================================================\n",
      "\n",
      "Comparison Summary DataFrame:\n",
      "           metric  TF-IDF_mean  TF-IDF_std  Embeddings_mean  Embeddings_std  difference  t_test_pvalue  wilcoxon_pvalue  TF-IDF_wins  Embeddings_wins\n",
      "  reciprocal_rank     0.982143    0.094491         0.815816        0.308144   -0.166327       0.004145         0.010712            8                0\n",
      "average_precision     0.292028    0.070579         0.229587        0.123098   -0.062441       0.001295         0.001285           22                5\n",
      "      precision@5     0.935714    0.144566         0.778571        0.337043   -0.157143       0.003860         0.005320           11                2\n",
      "         recall@5     0.081091    0.012833         0.065103        0.028665   -0.015988       0.005315         0.004676           18                6\n",
      "             f1@5     0.148444    0.020684         0.120025        0.052512   -0.028419       0.004043         0.004275           18                6\n",
      "           ndcg@5     0.817979    0.139303         0.673398        0.294579   -0.144581       0.013171         0.036602           17               10\n",
      "     precision@10     0.925000    0.145615         0.789286        0.317792   -0.135714       0.004922         0.004583           12                3\n",
      "        recall@10     0.161636    0.033727         0.133808        0.050234   -0.027828       0.006977         0.007423           18                7\n",
      "            f1@10     0.272397    0.043142         0.227494        0.086921   -0.044903       0.004675         0.006848           18                7\n",
      "          ndcg@10     0.852342    0.109085         0.725513        0.228286   -0.126829       0.007788         0.028795           17               10\n",
      "     precision@20     0.892857    0.187929         0.758929        0.319738   -0.133929       0.004542         0.002904           15                4\n",
      "        recall@20     0.308015    0.060794         0.253962        0.097169   -0.054053       0.002966         0.001005           20                6\n",
      "            f1@20     0.453305    0.083602         0.378622        0.149504   -0.074683       0.002283         0.001005           20                6\n",
      "          ndcg@20     0.932760    0.049893         0.845656        0.161553   -0.087105       0.006899         0.026357           18               10\n",
      "\n",
      "Evaluation results saved to CSV files\n",
      "Full evaluation results saved to 'evaluation_results.pkl'\n",
      "\n",
      "======================================================================\n",
      "INDIVIDUAL ENGINE EVALUATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "TF-IDF Engine:\n",
      "----------------------------------------\n",
      "  precision@5         : 0.9357 (±0.1446)\n",
      "  precision@10        : 0.9250 (±0.1456)\n",
      "  recall@10           : 0.1616 (±0.0337)\n",
      "  ndcg@10             : 0.8523 (±0.1091)\n",
      "  reciprocal_rank     : 0.9821 (±0.0945)\n",
      "  average_precision   : 0.2920 (±0.0706)\n",
      "\n",
      "Embeddings Engine:\n",
      "----------------------------------------\n",
      "  precision@5         : 0.7786 (±0.3370)\n",
      "  precision@10        : 0.7893 (±0.3178)\n",
      "  recall@10           : 0.1338 (±0.0502)\n",
      "  ndcg@10             : 0.7255 (±0.2283)\n",
      "  reciprocal_rank     : 0.8158 (±0.3081)\n",
      "  average_precision   : 0.2296 (±0.1231)\n",
      "\n",
      "======================================================================\n",
      "QUERY-TYPE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Performance by Query Type (NDCG@10):\n",
      "------------------------------------------------------------\n",
      "Query Type               TF-IDF      Embeddings       Winner\n",
      "------------------------------------------------------------\n",
      "keyword                  0.8671          0.9406   Embeddings\n",
      "semantic                 0.8893          0.6591       TF-IDF\n",
      "cuisine                  0.8188          0.7574       TF-IDF\n",
      "occasion                 0.9181          0.6905       TF-IDF\n",
      "mood                     0.7168          0.4311       TF-IDF\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# EVALUATION SYSTEM\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATION SYSTEM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# PROXY RELEVANCE GENERATOR\n",
    "# =============================================================================\n",
    "\n",
    "class ProxyRelevanceGenerator:\n",
    "    \"\"\"\n",
    "    Generates proxy relevance judgments for evaluation.\n",
    "    Since we don't have human annotations, we use multiple signals\n",
    "    to estimate relevance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, corpus_df: pd.DataFrame, metadata_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the relevance generator.\n",
    "        \n",
    "        Args:\n",
    "            corpus_df: DataFrame with recipe documents and tags\n",
    "            metadata_df: DataFrame with recipe metadata\n",
    "        \"\"\"\n",
    "        self.corpus_df = corpus_df.copy()\n",
    "        self.metadata_df = metadata_df.copy()\n",
    "        \n",
    "        # Precompute lowercase versions for matching\n",
    "        self.corpus_df['tags_lower'] = self.corpus_df['tags'].fillna('').astype(str).str.lower()\n",
    "        self.corpus_df['document_lower'] = self.corpus_df['document'].fillna('').astype(str).str.lower()\n",
    "        self.corpus_df['name_lower'] = self.corpus_df['recipe_name'].fillna('').astype(str).str.lower()\n",
    "        \n",
    "        self.metadata_df['name_lower'] = self.metadata_df['recipe_name'].fillna('').astype(str).str.lower()\n",
    "        self.metadata_df['desc_lower'] = self.metadata_df['description'].fillna('').astype(str).str.lower()\n",
    "        \n",
    "        # Create lookup dictionaries for fast access\n",
    "        # Much faster using to_dict\n",
    "        self.corpus_lookup = self.corpus_df.set_index('recipe_id')[\n",
    "            ['tags_lower', 'document_lower', 'name_lower']\n",
    "        ].to_dict('index')\n",
    "\n",
    "        self.metadata_lookup = self.metadata_df.set_index('recipe_id')[\n",
    "            ['name_lower', 'desc_lower']\n",
    "        ].to_dict('index')\n",
    "        \n",
    "        \n",
    "        print(f\"    Initialized relevance generator with {len(self.corpus_lookup)} recipes\")\n",
    "    \n",
    "    def _tokenize_query(self, query: str) -> List[str]:\n",
    "        \"\"\"Tokenize and clean query.\"\"\"\n",
    "        query = query.lower()\n",
    "        # Remove common stopwords for matching\n",
    "        stopwords_set = {'a', 'an', 'the', 'for', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'of', 'is', 'it'}\n",
    "        tokens = re.findall(r'\\b[a-z]+\\b', query)\n",
    "        tokens = [t for t in tokens if t not in stopwords_set and len(t) > 2]\n",
    "        return tokens\n",
    "    \n",
    "    def _compute_term_overlap(self, query_terms: List[str], text: str) -> float:\n",
    "        \"\"\"Compute the proportion of query terms found in text.\"\"\"\n",
    "        if not query_terms or not text:\n",
    "            return 0.0\n",
    "        \n",
    "        matches = sum(1 for term in query_terms if term in text)\n",
    "        return matches / len(query_terms)\n",
    "    \n",
    "    def compute_relevance_score(self, query: str, recipe_id: int) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute a multi-signal relevance score for a query-recipe pair.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            recipe_id: Recipe ID\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with relevance signals and overall score\n",
    "        \"\"\"\n",
    "        query_terms = self._tokenize_query(query)\n",
    "    \n",
    "        # Ensure recipe_id is a Python int\n",
    "        recipe_id = int(recipe_id)\n",
    "    \n",
    "        # Get recipe data\n",
    "        corpus_data = self.corpus_lookup.get(recipe_id, {})\n",
    "        meta_data = self.metadata_lookup.get(recipe_id, {})\n",
    "        \n",
    "        if not corpus_data and not meta_data:\n",
    "            return {'overall_score': 0.0, 'binary_relevant': False, 'graded_relevance': 0}\n",
    "        \n",
    "        # Signal 1: Tag matching (highest weight - tags are curated)\n",
    "        tags = corpus_data.get('tags_lower', '')\n",
    "        tag_score = self._compute_term_overlap(query_terms, tags)\n",
    "        \n",
    "        # Signal 2: Recipe name matching (high weight)\n",
    "        name = meta_data.get('name_lower', '') or corpus_data.get('name_lower', '')\n",
    "        name_score = self._compute_term_overlap(query_terms, name)\n",
    "        \n",
    "        # Signal 3: Description matching (medium weight)\n",
    "        desc = meta_data.get('desc_lower', '')\n",
    "        desc_score = self._compute_term_overlap(query_terms, desc)\n",
    "        \n",
    "        # Signal 4: Full document matching (lower weight - more noisy)\n",
    "        doc = corpus_data.get('document_lower', '')\n",
    "        doc_score = self._compute_term_overlap(query_terms, doc)\n",
    "        \n",
    "        # Compute weighted overall score\n",
    "        weights = {\n",
    "            'tag': 0.40,\n",
    "            'name': 0.30,\n",
    "            'desc': 0.20,\n",
    "            'doc': 0.10\n",
    "        }\n",
    "        \n",
    "        overall_score = (\n",
    "            weights['tag'] * tag_score +\n",
    "            weights['name'] * name_score +\n",
    "            weights['desc'] * desc_score +\n",
    "            weights['doc'] * doc_score\n",
    "        )\n",
    "        \n",
    "        # Binary relevance threshold\n",
    "        binary_relevant = (\n",
    "            tag_score >= 0.5 or \n",
    "            name_score >= 0.5 or \n",
    "            overall_score >= 0.3\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'tag_score': tag_score,\n",
    "            'name_score': name_score,\n",
    "            'desc_score': desc_score,\n",
    "            'doc_score': doc_score,\n",
    "            'overall_score': overall_score,\n",
    "            'binary_relevant': binary_relevant,\n",
    "            'graded_relevance': self._to_graded_relevance(overall_score)\n",
    "        }\n",
    "    \n",
    "    def _to_graded_relevance(self, score: float) -> int:\n",
    "        \"\"\"Convert continuous score to graded relevance (0-3).\"\"\"\n",
    "        if score >= 0.6:\n",
    "            return 3  # Highly relevant\n",
    "        elif score >= 0.4:\n",
    "            return 2  # Relevant\n",
    "        elif score >= 0.2:\n",
    "            return 1  # Partially relevant\n",
    "        else:\n",
    "            return 0  # Not relevant\n",
    "    \n",
    "    def generate_relevance_judgments(self, \n",
    "                                      query: str, \n",
    "                                      candidate_ids: List[int]) -> Dict[int, Dict]:\n",
    "        \"\"\"\n",
    "        Generate relevance judgments for a set of candidate recipes.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            candidate_ids: List of recipe IDs to judge\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping recipe_id to relevance scores\n",
    "        \"\"\"\n",
    "        judgments = {}\n",
    "        for recipe_id in candidate_ids:\n",
    "            judgments[recipe_id] = self.compute_relevance_score(query, recipe_id)\n",
    "        return judgments\n",
    "    \n",
    "    def get_pseudo_relevant_set(self, \n",
    "                                 query: str, \n",
    "                                 top_k: int = 100,\n",
    "                                 min_score: float = 0.3,\n",
    "                                 sample_size: int = 5000,\n",
    "                                 random_state: int=42) -> List[int]:\n",
    "        \"\"\"\n",
    "        Get a set of pseudo-relevant recipes for a query using text matching.\n",
    "        Uses sampling for efficiency on large datasets.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            top_k: Maximum number of relevant recipes to return\n",
    "            min_score: Minimum relevance score threshold\n",
    "            sample_size: Number of recipes to sample for evaluation\n",
    "            \n",
    "        Returns:\n",
    "            List of relevant recipe IDs\n",
    "        \"\"\"\n",
    "        query_terms = self._tokenize_query(query)\n",
    "        \n",
    "        if not query_terms:\n",
    "            return []\n",
    "        \n",
    "        # Sample recipes for efficiency\n",
    "        all_recipe_ids = list(self.corpus_lookup.keys())\n",
    "        if len(all_recipe_ids) > sample_size:\n",
    "            rng = np.random.RandomState(random_state)\n",
    "            sampled_ids = rng.choice(all_recipe_ids, size=sample_size, replace=False)\n",
    "        else:\n",
    "            sampled_ids = all_recipe_ids\n",
    "        \n",
    "        relevant_recipes = []\n",
    "        \n",
    "        for recipe_id in sampled_ids:\n",
    "            score_data = self.compute_relevance_score(query, recipe_id)\n",
    "            if score_data['overall_score'] >= min_score:\n",
    "                relevant_recipes.append((recipe_id, score_data['overall_score']))\n",
    "        \n",
    "        # Sort by score and return top-k\n",
    "        relevant_recipes.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [r[0] for r in relevant_recipes[:top_k]]\n",
    "    \n",
    "    def get_relevant_set_fast(self, \n",
    "                               query: str, \n",
    "                               retrieved_ids: List[int],\n",
    "                               min_score: float = 0.25) -> set:\n",
    "        \"\"\"\n",
    "        Get relevant set from retrieved candidates only (faster for evaluation).\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            retrieved_ids: List of retrieved recipe IDs to evaluate\n",
    "            min_score: Minimum relevance score threshold\n",
    "            \n",
    "        Returns:\n",
    "            Set of relevant recipe IDs\n",
    "        \"\"\"\n",
    "        query_terms = self._tokenize_query(query)\n",
    "        \n",
    "        if not query_terms:\n",
    "            return set()\n",
    "        \n",
    "        relevant = set()\n",
    "        for recipe_id in retrieved_ids:\n",
    "            score_data = self.compute_relevance_score(query, recipe_id)\n",
    "            if score_data['binary_relevant'] or score_data['overall_score'] >= min_score:\n",
    "                relevant.add(recipe_id)\n",
    "        \n",
    "        return relevant\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION METRICS\n",
    "# =============================================================================\n",
    "\n",
    "class SearchEngineEvaluator:\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation metrics for search engines.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, relevance_generator: ProxyRelevanceGenerator):\n",
    "        \"\"\"\n",
    "        Initialize evaluator.\n",
    "        \n",
    "        Args:\n",
    "            relevance_generator: ProxyRelevanceGenerator instance\n",
    "        \"\"\"\n",
    "        self.relevance_generator = relevance_generator\n",
    "    \n",
    "    def precision_at_k(self, \n",
    "                       retrieved_ids: List[int], \n",
    "                       relevant_ids: set, \n",
    "                       k: int) -> float:\n",
    "        \"\"\"\n",
    "        Compute Precision@K.\n",
    "        \n",
    "        Precision@K = (# of relevant docs in top-K) / K\n",
    "        \"\"\"\n",
    "        if k <= 0:\n",
    "            return 0.0\n",
    "        \n",
    "        retrieved_at_k = retrieved_ids[:k]\n",
    "        relevant_retrieved = sum(1 for doc_id in retrieved_at_k if doc_id in relevant_ids)\n",
    "        \n",
    "        return relevant_retrieved / k\n",
    "    \n",
    "    def recall_at_k(self, \n",
    "                    retrieved_ids: List[int], \n",
    "                    relevant_ids: set, \n",
    "                    k: int) -> float:\n",
    "        \"\"\"\n",
    "        Compute Recall@K.\n",
    "        \n",
    "        Recall@K = (# of relevant docs in top-K) / (total # of relevant docs)\n",
    "        \"\"\"\n",
    "        if not relevant_ids:\n",
    "            return 0.0\n",
    "        \n",
    "        retrieved_at_k = retrieved_ids[:k]\n",
    "        relevant_retrieved = sum(1 for doc_id in retrieved_at_k if doc_id in relevant_ids)\n",
    "        \n",
    "        return relevant_retrieved / len(relevant_ids)\n",
    "    \n",
    "    def average_precision(self, \n",
    "                          retrieved_ids: List[int], \n",
    "                          relevant_ids: set) -> float:\n",
    "        \"\"\"\n",
    "        Compute Average Precision (AP).\n",
    "        \n",
    "        AP = (1/R) * Σ(Precision@k * rel(k))\n",
    "        where R is total relevant docs and rel(k) is 1 if doc at rank k is relevant\n",
    "        \"\"\"\n",
    "        if not relevant_ids:\n",
    "            return 0.0\n",
    "        \n",
    "        num_relevant = 0\n",
    "        sum_precision = 0.0\n",
    "        \n",
    "        for k, doc_id in enumerate(retrieved_ids, 1):\n",
    "            if doc_id in relevant_ids:\n",
    "                num_relevant += 1\n",
    "                precision_at_k = num_relevant / k\n",
    "                sum_precision += precision_at_k\n",
    "        \n",
    "        if num_relevant == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return sum_precision / len(relevant_ids)\n",
    "    \n",
    "    def reciprocal_rank(self, \n",
    "                        retrieved_ids: List[int], \n",
    "                        relevant_ids: set) -> float:\n",
    "        \"\"\"\n",
    "        Compute Reciprocal Rank (RR).\n",
    "        \n",
    "        RR = 1 / (rank of first relevant document)\n",
    "        \"\"\"\n",
    "        for rank, doc_id in enumerate(retrieved_ids, 1):\n",
    "            if doc_id in relevant_ids:\n",
    "                return 1.0 / rank\n",
    "        return 0.0\n",
    "    \n",
    "    def dcg_at_k(self, \n",
    "                 retrieved_ids: List[int], \n",
    "                 relevance_scores: Dict[int, int], \n",
    "                 k: int) -> float:\n",
    "        \"\"\"\n",
    "        Compute Discounted Cumulative Gain (DCG) at K.\n",
    "        \n",
    "        DCG@K = Σ(rel_i / log2(i + 1)) for i = 1 to K\n",
    "        \"\"\"\n",
    "        dcg = 0.0\n",
    "        for i, doc_id in enumerate(retrieved_ids[:k], 1):\n",
    "            rel = relevance_scores.get(doc_id, 0)\n",
    "            dcg += rel / np.log2(i + 1)\n",
    "        return dcg\n",
    "    \n",
    "    def ndcg_at_k(self, \n",
    "                  retrieved_ids: List[int], \n",
    "                  relevance_scores: Dict[int, int], \n",
    "                  k: int) -> float:\n",
    "        \"\"\"\n",
    "        Compute Normalized Discounted Cumulative Gain (NDCG) at K.\n",
    "        \n",
    "        NDCG@K = DCG@K / IDCG@K\n",
    "        where IDCG is the ideal DCG (perfect ranking)\n",
    "        \"\"\"\n",
    "        # Compute DCG\n",
    "        dcg = self.dcg_at_k(retrieved_ids, relevance_scores, k)\n",
    "        \n",
    "        # Compute IDCG (ideal ranking)\n",
    "        ideal_ranking = sorted(relevance_scores.values(), reverse=True)[:k]\n",
    "        idcg = 0.0\n",
    "        for i, rel in enumerate(ideal_ranking, 1):\n",
    "            idcg += rel / np.log2(i + 1)\n",
    "        \n",
    "        if idcg == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return dcg / idcg\n",
    "    \n",
    "    def f1_at_k(self, \n",
    "                retrieved_ids: List[int], \n",
    "                relevant_ids: set, \n",
    "                k: int) -> float:\n",
    "        \"\"\"\n",
    "        Compute F1 score at K.\n",
    "        \n",
    "        F1@K = 2 * (Precision@K * Recall@K) / (Precision@K + Recall@K)\n",
    "        \"\"\"\n",
    "        p = self.precision_at_k(retrieved_ids, relevant_ids, k)\n",
    "        r = self.recall_at_k(retrieved_ids, relevant_ids, k)\n",
    "        \n",
    "        if p + r == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return 2 * (p * r) / (p + r)\n",
    "    \n",
    "    def evaluate_single_query(self, \n",
    "                               query: str, \n",
    "                               retrieved_results: List[Tuple[int, float]], \n",
    "                               k_values: List[int] = [5, 10, 20]) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate a single query's results.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            retrieved_results: List of (recipe_id, score) tuples\n",
    "            k_values: List of K values for metrics\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        retrieved_ids = [r[0] for r in retrieved_results]\n",
    "        \n",
    "        if not retrieved_ids:\n",
    "            # Return zeros if no results\n",
    "            results = {\n",
    "                'query': query,\n",
    "                'num_retrieved': 0,\n",
    "                'num_relevant_in_corpus': 0,\n",
    "                'reciprocal_rank': 0.0,\n",
    "                'average_precision': 0.0\n",
    "            }\n",
    "            for k in k_values:\n",
    "                results[f'precision@{k}'] = 0.0\n",
    "                results[f'recall@{k}'] = 0.0\n",
    "                results[f'f1@{k}'] = 0.0\n",
    "                results[f'ndcg@{k}'] = 0.0\n",
    "            return results\n",
    "        \n",
    "        # Get relevant set from retrieved candidates (faster than full corpus scan)\n",
    "        relevant_ids = self.relevance_generator.get_relevant_set_fast(\n",
    "            query, retrieved_ids, min_score=0.25\n",
    "        )\n",
    "        \n",
    "        # Also check a sample for better recall estimation\n",
    "        sample_relevant = self.relevance_generator.get_pseudo_relevant_set(\n",
    "            query, top_k=50, min_score=0.25, sample_size=2000, random_state=2\n",
    "        )\n",
    "        relevant_ids.update(sample_relevant)\n",
    "        \n",
    "        # Get graded relevance for NDCG\n",
    "        judgments = self.relevance_generator.generate_relevance_judgments(\n",
    "            query, retrieved_ids\n",
    "        )\n",
    "        graded_relevance = {\n",
    "            rid: j['graded_relevance'] for rid, j in judgments.items()\n",
    "        }\n",
    "        \n",
    "        # Compute metrics\n",
    "        results = {\n",
    "            'query': query,\n",
    "            'num_retrieved': len(retrieved_ids),\n",
    "            'num_relevant_in_corpus': len(relevant_ids),\n",
    "            'reciprocal_rank': self.reciprocal_rank(retrieved_ids, relevant_ids),\n",
    "            'average_precision': self.average_precision(retrieved_ids, relevant_ids)\n",
    "        }\n",
    "        \n",
    "        # Compute metrics at different K values\n",
    "        for k in k_values:\n",
    "            results[f'precision@{k}'] = self.precision_at_k(retrieved_ids, relevant_ids, k)\n",
    "            results[f'recall@{k}'] = self.recall_at_k(retrieved_ids, relevant_ids, k)\n",
    "            results[f'f1@{k}'] = self.f1_at_k(retrieved_ids, relevant_ids, k)\n",
    "            results[f'ndcg@{k}'] = self.ndcg_at_k(retrieved_ids, graded_relevance, k)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_engine(self, \n",
    "                        search_engine, \n",
    "                        queries: List[str], \n",
    "                        top_k: int = 20,\n",
    "                        k_values: List[int] = [5, 10, 20],\n",
    "                        engine_name: str = \"Engine\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Evaluate a search engine across multiple queries.\n",
    "        \n",
    "        Args:\n",
    "            search_engine: Search engine with search() method\n",
    "            queries: List of queries to evaluate\n",
    "            top_k: Number of results to retrieve per query\n",
    "            k_values: List of K values for metrics\n",
    "            engine_name: Name of the engine for reporting\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with evaluation results\n",
    "        \"\"\"\n",
    "        print(f\"\\n    Evaluating {engine_name}...\")\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        for query in tqdm(queries, desc=f\"    {engine_name}\"):\n",
    "            try:\n",
    "                # Get search results\n",
    "                search_results = search_engine.search(query, top_k=top_k)\n",
    "                \n",
    "                # Evaluate\n",
    "                metrics = self.evaluate_single_query(query, search_results, k_values)\n",
    "                metrics['engine'] = engine_name\n",
    "                all_results.append(metrics)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Error evaluating query '{query}': {e}\")\n",
    "                # Add a row with zeros for failed queries\n",
    "                failed_metrics = {\n",
    "                    'query': query,\n",
    "                    'engine': engine_name,\n",
    "                    'num_retrieved': 0,\n",
    "                    'num_relevant_in_corpus': 0,\n",
    "                    'reciprocal_rank': 0.0,\n",
    "                    'average_precision': 0.0\n",
    "                }\n",
    "                for k in k_values:\n",
    "                    failed_metrics[f'precision@{k}'] = 0.0\n",
    "                    failed_metrics[f'recall@{k}'] = 0.0\n",
    "                    failed_metrics[f'f1@{k}'] = 0.0\n",
    "                    failed_metrics[f'ndcg@{k}'] = 0.0\n",
    "                all_results.append(failed_metrics)\n",
    "        \n",
    "        if not all_results:\n",
    "            print(f\"    Warning: No results for {engine_name}\")\n",
    "            # Return empty dataframe with correct columns\n",
    "            columns = ['query', 'engine', 'num_retrieved', 'num_relevant_in_corpus',\n",
    "                      'reciprocal_rank', 'average_precision']\n",
    "            for k in k_values:\n",
    "                columns.extend([f'precision@{k}', f'recall@{k}', f'f1@{k}', f'ndcg@{k}'])\n",
    "            return pd.DataFrame(columns=columns)\n",
    "        \n",
    "        return pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENGINE COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "class EngineComparator:\n",
    "    \"\"\"\n",
    "    Statistical comparison between search engines.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, evaluator: SearchEngineEvaluator):\n",
    "        \"\"\"\n",
    "        Initialize comparator.\n",
    "        \n",
    "        Args:\n",
    "            evaluator: SearchEngineEvaluator instance\n",
    "        \"\"\"\n",
    "        self.evaluator = evaluator\n",
    "    \n",
    "    def compare_engines(self, \n",
    "                        engine1, \n",
    "                        engine2, \n",
    "                        queries: List[str],\n",
    "                        engine1_name: str = \"TF-IDF\",\n",
    "                        engine2_name: str = \"Embeddings\",\n",
    "                        top_k: int = 20,\n",
    "                        k_values: List[int] = [5, 10, 20]) -> Dict:\n",
    "        \"\"\"\n",
    "        Compare two search engines across multiple queries.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"ENGINE COMPARISON\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Evaluate both engines\n",
    "        results1 = self.evaluator.evaluate_engine(\n",
    "            engine1, queries, top_k, k_values, engine1_name\n",
    "        )\n",
    "        results2 = self.evaluator.evaluate_engine(\n",
    "            engine2, queries, top_k, k_values, engine2_name\n",
    "        )\n",
    "        \n",
    "        # Debug: print shape and columns\n",
    "        print(f\"\\n    {engine1_name} results shape: {results1.shape}\")\n",
    "        print(f\"    {engine2_name} results shape: {results2.shape}\")\n",
    "        \n",
    "        if results1.empty or results2.empty:\n",
    "            print(\"    Warning: One or both engines returned no results!\")\n",
    "            return {\n",
    "                'individual_results': pd.concat([results1, results2], ignore_index=True),\n",
    "                'engine1_name': engine1_name,\n",
    "                'engine2_name': engine2_name,\n",
    "                'queries': queries,\n",
    "                'summary': {},\n",
    "                'statistical_tests': {},\n",
    "                'overlap_analysis': {}\n",
    "            }\n",
    "        \n",
    "        # Combine results\n",
    "        all_results = pd.concat([results1, results2], ignore_index=True)\n",
    "        \n",
    "        # Compute aggregate statistics\n",
    "        comparison = {\n",
    "            'individual_results': all_results,\n",
    "            'engine1_name': engine1_name,\n",
    "            'engine2_name': engine2_name,\n",
    "            'queries': queries,\n",
    "            'summary': {},\n",
    "            'statistical_tests': {},\n",
    "            'overlap_analysis': {}\n",
    "        }\n",
    "        \n",
    "        # Compute summary statistics\n",
    "        metric_columns = [col for col in results1.columns \n",
    "                         if col not in ['query', 'engine', 'num_retrieved', 'num_relevant_in_corpus']]\n",
    "        \n",
    "        summary = {}\n",
    "        for metric in metric_columns:\n",
    "            if metric in results1.columns and metric in results2.columns:\n",
    "                summary[metric] = {\n",
    "                    engine1_name: {\n",
    "                        'mean': float(results1[metric].mean()),\n",
    "                        'std': float(results1[metric].std()),\n",
    "                        'median': float(results1[metric].median()),\n",
    "                        'min': float(results1[metric].min()),\n",
    "                        'max': float(results1[metric].max())\n",
    "                    },\n",
    "                    engine2_name: {\n",
    "                        'mean': float(results2[metric].mean()),\n",
    "                        'std': float(results2[metric].std()),\n",
    "                        'median': float(results2[metric].median()),\n",
    "                        'min': float(results2[metric].min()),\n",
    "                        'max': float(results2[metric].max())\n",
    "                    }\n",
    "                }\n",
    "        comparison['summary'] = summary\n",
    "        \n",
    "        # Statistical significance tests\n",
    "        print(\"\\n    Running statistical tests...\")\n",
    "        stat_tests = {}\n",
    "        for metric in metric_columns:\n",
    "            if metric not in results1.columns or metric not in results2.columns:\n",
    "                continue\n",
    "                \n",
    "            values1 = results1[metric].values\n",
    "            values2 = results2[metric].values\n",
    "            \n",
    "            # Ensure same length\n",
    "            min_len = min(len(values1), len(values2))\n",
    "            values1 = values1[:min_len]\n",
    "            values2 = values2[:min_len]\n",
    "            \n",
    "            # Paired t-test\n",
    "            try:\n",
    "                t_stat, t_pvalue = stats.ttest_rel(values1, values2)\n",
    "            except Exception:\n",
    "                t_stat, t_pvalue = np.nan, np.nan\n",
    "            \n",
    "            # Wilcoxon signed-rank test (non-parametric)\n",
    "            try:\n",
    "                # Check if there's any variance\n",
    "                diff = values1 - values2\n",
    "                if np.all(diff == 0):\n",
    "                    w_stat, w_pvalue = np.nan, np.nan\n",
    "                else:\n",
    "                    w_stat, w_pvalue = stats.wilcoxon(values1, values2)\n",
    "            except Exception:\n",
    "                w_stat, w_pvalue = np.nan, np.nan\n",
    "            \n",
    "            stat_tests[metric] = {\n",
    "                'paired_ttest': {'statistic': float(t_stat) if not np.isnan(t_stat) else None, \n",
    "                                'pvalue': float(t_pvalue) if not np.isnan(t_pvalue) else None},\n",
    "                'wilcoxon': {'statistic': float(w_stat) if not np.isnan(w_stat) else None, \n",
    "                            'pvalue': float(w_pvalue) if not np.isnan(w_pvalue) else None},\n",
    "                'engine1_wins': int(np.sum(values1 > values2)),\n",
    "                'engine2_wins': int(np.sum(values2 > values1)),\n",
    "                'ties': int(np.sum(values1 == values2))\n",
    "            }\n",
    "        \n",
    "        comparison['statistical_tests'] = stat_tests\n",
    "        \n",
    "        # Overlap analysis\n",
    "        print(\"\\n    Computing overlap analysis...\")\n",
    "        overlap_analysis = self._compute_overlap_analysis(\n",
    "            engine1, engine2, queries, top_k, engine1_name, engine2_name\n",
    "        )\n",
    "        comparison['overlap_analysis'] = overlap_analysis\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def _compute_overlap_analysis(self, \n",
    "                                   engine1, \n",
    "                                   engine2, \n",
    "                                   queries: List[str],\n",
    "                                   top_k: int,\n",
    "                                   engine1_name: str,\n",
    "                                   engine2_name: str) -> Dict:\n",
    "        \"\"\"Compute result overlap between engines.\"\"\"\n",
    "        overlaps = []\n",
    "        rank_correlations = []\n",
    "        \n",
    "        for query in queries:\n",
    "            try:\n",
    "                results1 = engine1.search(query, top_k=top_k)\n",
    "                results2 = engine2.search(query, top_k=top_k)\n",
    "                \n",
    "                ids1 = set(r[0] for r in results1)\n",
    "                ids2 = set(r[0] for r in results2)\n",
    "                \n",
    "                # Jaccard overlap\n",
    "                intersection = len(ids1 & ids2)\n",
    "                union = len(ids1 | ids2)\n",
    "                jaccard = intersection / union if union > 0 else 0\n",
    "                \n",
    "                overlaps.append({\n",
    "                    'query': query,\n",
    "                    'overlap_count': intersection,\n",
    "                    'jaccard_similarity': jaccard,\n",
    "                    f'{engine1_name}_unique': len(ids1 - ids2),\n",
    "                    f'{engine2_name}_unique': len(ids2 - ids1)\n",
    "                })\n",
    "                \n",
    "                # Rank correlation for common items\n",
    "                common_ids = list(ids1 & ids2)\n",
    "                if len(common_ids) >= 3:\n",
    "                    rank1 = {r[0]: i for i, r in enumerate(results1)}\n",
    "                    rank2 = {r[0]: i for i, r in enumerate(results2)}\n",
    "                    \n",
    "                    ranks1 = [rank1[id_] for id_ in common_ids]\n",
    "                    ranks2 = [rank2[id_] for id_ in common_ids]\n",
    "                    \n",
    "                    try:\n",
    "                        spearman_corr, _ = spearmanr(ranks1, ranks2)\n",
    "                        kendall_corr, _ = kendalltau(ranks1, ranks2)\n",
    "                        \n",
    "                        rank_correlations.append({\n",
    "                            'query': query,\n",
    "                            'spearman': spearman_corr,\n",
    "                            'kendall': kendall_corr,\n",
    "                            'num_common': len(common_ids)\n",
    "                        })\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Overlap analysis failed for '{query}': {e}\")\n",
    "                continue\n",
    "        \n",
    "        overlap_df = pd.DataFrame(overlaps) if overlaps else pd.DataFrame()\n",
    "        rank_corr_df = pd.DataFrame(rank_correlations) if rank_correlations else pd.DataFrame()\n",
    "        \n",
    "        return {\n",
    "            'per_query_overlap': overlap_df,\n",
    "            'rank_correlations': rank_corr_df,\n",
    "            'mean_jaccard': float(overlap_df['jaccard_similarity'].mean()) if len(overlap_df) > 0 else 0,\n",
    "            'mean_overlap_count': float(overlap_df['overlap_count'].mean()) if len(overlap_df) > 0 else 0,\n",
    "            'mean_spearman': float(rank_corr_df['spearman'].mean()) if len(rank_corr_df) > 0 else np.nan,\n",
    "            'mean_kendall': float(rank_corr_df['kendall'].mean()) if len(rank_corr_df) > 0 else np.nan\n",
    "        }\n",
    "    \n",
    "    def print_comparison_report(self, comparison: Dict) -> None:\n",
    "        \"\"\"Print a formatted comparison report.\"\"\"\n",
    "        engine1 = comparison['engine1_name']\n",
    "        engine2 = comparison['engine2_name']\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"COMPARISON REPORT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(f\"\\nEngines: {engine1} vs {engine2}\")\n",
    "        print(f\"Number of queries: {len(comparison['queries'])}\")\n",
    "        \n",
    "        summary = comparison['summary']\n",
    "        stat_tests = comparison['statistical_tests']\n",
    "        \n",
    "        if not summary:\n",
    "            print(\"\\nNo evaluation results available.\")\n",
    "            return\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        key_metrics = ['precision@10', 'recall@10', 'ndcg@10', 'reciprocal_rank', 'average_precision']\n",
    "        \n",
    "        print(f\"\\n{'Metric':<25} {engine1:>20} {engine2:>20} {'Winner':>12}\")\n",
    "        print(\"-\" * 77)\n",
    "        \n",
    "        for metric in key_metrics:\n",
    "            if metric in summary:\n",
    "                mean1 = summary[metric][engine1]['mean']\n",
    "                mean2 = summary[metric][engine2]['mean']\n",
    "                winner = engine1 if mean1 > mean2 else engine2 if mean2 > mean1 else \"Tie\"\n",
    "                print(f\"{metric:<25} {mean1:>20.4f} {mean2:>20.4f} {winner:>12}\")\n",
    "        \n",
    "        # Statistical tests\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"STATISTICAL SIGNIFICANCE (p-value < 0.05 is significant)\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        print(f\"\\n{'Metric':<25} {'t-test p-val':>15} {'Wilcoxon p-val':>15} {'Significant?':>15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for metric in key_metrics:\n",
    "            if metric in stat_tests:\n",
    "                t_pval = stat_tests[metric]['paired_ttest']['pvalue']\n",
    "                w_pval = stat_tests[metric]['wilcoxon']['pvalue']\n",
    "                \n",
    "                t_pval_str = f\"{t_pval:.4f}\" if t_pval is not None else \"N/A\"\n",
    "                w_pval_str = f\"{w_pval:.4f}\" if w_pval is not None else \"N/A\"\n",
    "                \n",
    "                significant = \"No\"\n",
    "                if t_pval is not None and t_pval < 0.05:\n",
    "                    significant = \"Yes\"\n",
    "                elif w_pval is not None and w_pval < 0.05:\n",
    "                    significant = \"Yes\"\n",
    "                \n",
    "                print(f\"{metric:<25} {t_pval_str:>15} {w_pval_str:>15} {significant:>15}\")\n",
    "        \n",
    "        # Win/Loss analysis\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"WIN/LOSS ANALYSIS\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        print(f\"\\n{'Metric':<25} {engine1 + ' Wins':>15} {engine2 + ' Wins':>15} {'Ties':>10}\")\n",
    "        print(\"-\" * 65)\n",
    "        \n",
    "        for metric in key_metrics:\n",
    "            if metric in stat_tests:\n",
    "                e1_wins = stat_tests[metric]['engine1_wins']\n",
    "                e2_wins = stat_tests[metric]['engine2_wins']\n",
    "                ties = stat_tests[metric]['ties']\n",
    "                print(f\"{metric:<25} {e1_wins:>15} {e2_wins:>15} {ties:>10}\")\n",
    "        \n",
    "        # Overlap analysis\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"OVERLAP ANALYSIS\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        overlap = comparison['overlap_analysis']\n",
    "        print(f\"\\nMean Jaccard Similarity: {overlap['mean_jaccard']:.4f}\")\n",
    "        print(f\"Mean Overlap Count (top-20): {overlap['mean_overlap_count']:.1f}\")\n",
    "        if not np.isnan(overlap['mean_spearman']):\n",
    "            print(f\"Mean Spearman Rank Correlation: {overlap['mean_spearman']:.4f}\")\n",
    "            print(f\"Mean Kendall Rank Correlation: {overlap['mean_kendall']:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"END OF COMPARISON REPORT\")\n",
    "        print(\"=\" * 70)\n",
    "    \n",
    "    def get_comparison_dataframe(self, comparison: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Convert comparison results to a summary DataFrame.\"\"\"\n",
    "        rows = []\n",
    "        \n",
    "        engine1 = comparison['engine1_name']\n",
    "        engine2 = comparison['engine2_name']\n",
    "        summary = comparison['summary']\n",
    "        stat_tests = comparison['statistical_tests']\n",
    "        \n",
    "        for metric in summary.keys():\n",
    "            t_pval = None\n",
    "            w_pval = None\n",
    "            e1_wins = 0\n",
    "            e2_wins = 0\n",
    "            \n",
    "            if metric in stat_tests:\n",
    "                t_pval = stat_tests[metric]['paired_ttest']['pvalue']\n",
    "                w_pval = stat_tests[metric]['wilcoxon']['pvalue']\n",
    "                e1_wins = stat_tests[metric]['engine1_wins']\n",
    "                e2_wins = stat_tests[metric]['engine2_wins']\n",
    "            \n",
    "            row = {\n",
    "                'metric': metric,\n",
    "                f'{engine1}_mean': summary[metric][engine1]['mean'],\n",
    "                f'{engine1}_std': summary[metric][engine1]['std'],\n",
    "                f'{engine2}_mean': summary[metric][engine2]['mean'],\n",
    "                f'{engine2}_std': summary[metric][engine2]['std'],\n",
    "                'difference': summary[metric][engine2]['mean'] - summary[metric][engine1]['mean'],\n",
    "                't_test_pvalue': t_pval,\n",
    "                'wilcoxon_pvalue': w_pval,\n",
    "                f'{engine1}_wins': e1_wins,\n",
    "                f'{engine2}_wins': e2_wins\n",
    "            }\n",
    "            rows.append(row)\n",
    "        \n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RUN EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RUNNING EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize relevance generator\n",
    "print(\"\\nInitializing proxy relevance generator...\")\n",
    "relevance_generator = ProxyRelevanceGenerator(corpus_df, metadata_df)\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = SearchEngineEvaluator(relevance_generator)\n",
    "\n",
    "# Define evaluation queries - mix of different types\n",
    "evaluation_queries = [\n",
    "    # Simple keyword queries\n",
    "    \"chocolate cake\",\n",
    "    \"pasta carbonara\",\n",
    "    \"chicken soup\",\n",
    "    \"banana bread\",\n",
    "    \"grilled salmon\",\n",
    "    \"beef stew\",\n",
    "    \"apple pie\",\n",
    "    \"caesar salad\",\n",
    "    \n",
    "    # Semantic/conceptual queries\n",
    "    \"comfort food for a rainy day\",\n",
    "    \"healthy dinner after gym\",\n",
    "    \"quick and easy breakfast\",\n",
    "    \"romantic dinner for two\",\n",
    "    \"light summer salad\",\n",
    "    \"warm winter soup\",\n",
    "    \"kid friendly lunch\",\n",
    "    \"low carb vegetarian\",\n",
    "    \n",
    "    # Cuisine-based queries\n",
    "    \"italian pasta dish\",\n",
    "    \"mexican dinner\",\n",
    "    \"asian stir fry\",\n",
    "    \"mediterranean lunch\",\n",
    "    \n",
    "    # Occasion-based queries\n",
    "    \"holiday dessert\",\n",
    "    \"birthday cake\",\n",
    "    \"party appetizer\",\n",
    "    \"sunday brunch\",\n",
    "    \n",
    "    # Mood/attribute queries\n",
    "    \"something sweet and indulgent\",\n",
    "    \"quick weeknight meal\",\n",
    "    \"impressive dish for guests\",\n",
    "    \"healthy meal prep\"\n",
    "]\n",
    "\n",
    "print(f\"\\nEvaluating {len(evaluation_queries)} queries...\")\n",
    "\n",
    "# Initialize comparator\n",
    "comparator = EngineComparator(evaluator)\n",
    "\n",
    "# Run comparison\n",
    "comparison_results = comparator.compare_engines(\n",
    "    engine1=tfidf_engine,\n",
    "    engine2=embeddings_engine,\n",
    "    queries=evaluation_queries,\n",
    "    engine1_name=\"TF-IDF\",\n",
    "    engine2_name=\"Embeddings\",\n",
    "    top_k=20,\n",
    "    k_values=[5, 10, 20]\n",
    ")\n",
    "\n",
    "# Print comparison report\n",
    "comparator.print_comparison_report(comparison_results)\n",
    "\n",
    "# Get comparison DataFrame\n",
    "comparison_df = comparator.get_comparison_dataframe(comparison_results)\n",
    "print(\"\\nComparison Summary DataFrame:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save evaluation results\n",
    "comparison_df.to_csv(\"evaluation_comparison.csv\", index=False)\n",
    "comparison_results['individual_results'].to_csv(\"evaluation_individual_results.csv\", index=False)\n",
    "print(\"\\nEvaluation results saved to CSV files\")\n",
    "\n",
    "# Save full comparison results\n",
    "with open(\"evaluation_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comparison_results, f)\n",
    "print(\"Full evaluation results saved to 'evaluation_results.pkl'\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INDIVIDUAL ENGINE EVALUATION SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INDIVIDUAL ENGINE EVALUATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "individual_results = comparison_results['individual_results']\n",
    "\n",
    "# Check if results are valid\n",
    "if individual_results.empty or 'engine' not in individual_results.columns:\n",
    "    print(\"\\nWarning: No evaluation results available.\")\n",
    "else:\n",
    "    for engine_name in ['TF-IDF', 'Embeddings']:\n",
    "        engine_results = individual_results[individual_results['engine'] == engine_name]\n",
    "        \n",
    "        if engine_results.empty:\n",
    "            print(f\"\\n{engine_name} Engine: No results\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{engine_name} Engine:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        metrics_to_show = ['precision@5', 'precision@10', 'recall@10', 'ndcg@10', 'reciprocal_rank', 'average_precision']\n",
    "        \n",
    "        for metric in metrics_to_show:\n",
    "            if metric in engine_results.columns:\n",
    "                mean_val = engine_results[metric].mean()\n",
    "                std_val = engine_results[metric].std()\n",
    "                print(f\"  {metric:<20}: {mean_val:.4f} (±{std_val:.4f})\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# QUERY-TYPE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"QUERY-TYPE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Categorize queries\n",
    "query_categories = {\n",
    "    'keyword': [\n",
    "        \"chocolate cake\", \"pasta carbonara\", \"chicken soup\", \"banana bread\",\n",
    "        \"grilled salmon\", \"beef stew\", \"apple pie\", \"caesar salad\"\n",
    "    ],\n",
    "    'semantic': [\n",
    "        \"comfort food for a rainy day\", \"healthy dinner after gym\",\n",
    "        \"quick and easy breakfast\", \"romantic dinner for two\",\n",
    "        \"light summer salad\", \"warm winter soup\", \"kid friendly lunch\",\n",
    "        \"low carb vegetarian\"\n",
    "    ],\n",
    "    'cuisine': [\n",
    "        \"italian pasta dish\", \"mexican dinner\", \"asian stir fry\", \"mediterranean lunch\"\n",
    "    ],\n",
    "    'occasion': [\n",
    "        \"holiday dessert\", \"birthday cake\", \"party appetizer\", \"sunday brunch\"\n",
    "    ],\n",
    "    'mood': [\n",
    "        \"something sweet and indulgent\", \"quick weeknight meal\",\n",
    "        \"impressive dish for guests\", \"healthy meal prep\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "if not individual_results.empty and 'engine' in individual_results.columns:\n",
    "    print(\"\\nPerformance by Query Type (NDCG@10):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Query Type':<15} {'TF-IDF':>15} {'Embeddings':>15} {'Winner':>12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for category, queries in query_categories.items():\n",
    "        cat_results = individual_results[individual_results['query'].isin(queries)]\n",
    "        \n",
    "        if cat_results.empty:\n",
    "            print(f\"{category:<15} {'N/A':>15} {'N/A':>15} {'N/A':>12}\")\n",
    "            continue\n",
    "        \n",
    "        tfidf_results = cat_results[cat_results['engine'] == 'TF-IDF']\n",
    "        embed_results = cat_results[cat_results['engine'] == 'Embeddings']\n",
    "        \n",
    "        tfidf_ndcg = tfidf_results['ndcg@10'].mean() if not tfidf_results.empty else 0\n",
    "        embed_ndcg = embed_results['ndcg@10'].mean() if not embed_results.empty else 0\n",
    "        \n",
    "        winner = \"TF-IDF\" if tfidf_ndcg > embed_ndcg else \"Embeddings\" if embed_ndcg > tfidf_ndcg else \"Tie\"\n",
    "        \n",
    "        print(f\"{category:<15} {tfidf_ndcg:>15.4f} {embed_ndcg:>15.4f} {winner:>12}\")\n",
    "else:\n",
    "    print(\"\\nNo results available for query-type analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7dfee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING SIMPLE GUI\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95806697f60645439c7c271362a98816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e08dd50ec84a58a75727529b505c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SIMPLE GUI APPLICATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INITIALIZING SIMPLE GUI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "class SimpleRecipeSearchApp:\n",
    "    \"\"\"Simple GUI for Recipe Search Engine.\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Recipe Search Engine\")\n",
    "        self.root.geometry(\"800x600\")\n",
    "        \n",
    "        # ----- Search Frame -----\n",
    "        search_frame = tk.Frame(root, pady=10)\n",
    "        search_frame.pack(fill=tk.X, padx=10)\n",
    "        \n",
    "        # Search entry\n",
    "        self.search_entry = tk.Entry(search_frame, font=('Arial', 12), width=50)\n",
    "        self.search_entry.pack(side=tk.LEFT, padx=(0, 10))\n",
    "        self.search_entry.insert(0, \"comfort food\")\n",
    "        \n",
    "        # Engine selection\n",
    "        self.engine_var = tk.StringVar(value=\"Embeddings\")\n",
    "        tk.Radiobutton(search_frame, text=\"TF-IDF\", variable=self.engine_var, value=\"TF-IDF\").pack(side=tk.LEFT)\n",
    "        tk.Radiobutton(search_frame, text=\"Embeddings\", variable=self.engine_var, value=\"Embeddings\").pack(side=tk.LEFT)\n",
    "        \n",
    "        # Search button\n",
    "        self.search_btn = tk.Button(search_frame, text=\"Search\", font=('Arial', 11), command=self.search)\n",
    "        self.search_btn.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # ----- Results Area -----\n",
    "        self.results_text = scrolledtext.ScrolledText(root, font=('Arial', 10), wrap=tk.WORD)\n",
    "        self.results_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Bind Enter key\n",
    "        self.root.bind('<Return>', lambda e: self.search())\n",
    "    \n",
    "    def search(self):\n",
    "        \"\"\"Perform search and display results.\"\"\"\n",
    "        query = self.search_entry.get().strip()\n",
    "        \n",
    "        if not query:\n",
    "            self.results_text.delete('1.0', tk.END)\n",
    "            self.results_text.insert(tk.END, \"Please enter a search query.\")\n",
    "            return\n",
    "        \n",
    "        # Clear results\n",
    "        self.results_text.delete('1.0', tk.END)\n",
    "        self.results_text.insert(tk.END, \"Searching...\\n\")\n",
    "        self.root.update()\n",
    "        \n",
    "        try:\n",
    "            # Get results based on selected engine\n",
    "            if self.engine_var.get() == \"TF-IDF\":\n",
    "                results = tfidf_engine.search(query, top_k=10)\n",
    "                engine_name = \"TF-IDF\"\n",
    "            else:\n",
    "                results = embeddings_engine.search(query, top_k=10)\n",
    "                engine_name = \"Embeddings\"\n",
    "            \n",
    "            # Display results\n",
    "            self.results_text.delete('1.0', tk.END)\n",
    "            self.results_text.insert(tk.END, f\"=== {engine_name} Results for: '{query}' ===\\n\\n\")\n",
    "            \n",
    "            if not results:\n",
    "                self.results_text.insert(tk.END, \"No results found.\")\n",
    "                return\n",
    "            \n",
    "            for i, (recipe_id, score) in enumerate(results, 1):\n",
    "                # Get recipe info\n",
    "                meta = metadata_df[metadata_df['recipe_id'] == recipe_id]\n",
    "                \n",
    "                if len(meta) == 0:\n",
    "                    continue\n",
    "                \n",
    "                meta = meta.iloc[0]\n",
    "                name = meta['recipe_name']\n",
    "                time = meta['cooking_time']\n",
    "                ingredients = meta['num_ingredients']\n",
    "                \n",
    "                # Display\n",
    "                self.results_text.insert(tk.END, f\"{i}. {name}\\n\")\n",
    "                self.results_text.insert(tk.END, f\"   Score: {score:.4f} | Time: {time} min | Ingredients: {ingredients}\\n\\n\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.results_text.delete('1.0', tk.END)\n",
    "            self.results_text.insert(tk.END, f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = SimpleRecipeSearchApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fb9416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SEARCH RESULTS FOR: 'easy meal for kids'\n",
      "======================================================================\n",
      "\n",
      "[1] cheesy chicken sandwiches\n",
      "    Score: 0.2589\n",
      "    Cooking Time: 20 min | Ingredients: 5 | Steps: 5\n",
      "    Description: a quick and easy meal and a kid pleaser!...\n",
      "\n",
      "[2] chicken pesto pasta\n",
      "    Score: 0.1039\n",
      "    Cooking Time: 30 min | Ingredients: 7 | Steps: 9\n",
      "    Description: found this recipe on allrecipes.com. a very simple recipe for a tasty, satisfying pasta meal. you can make your own homemade pesto, or use store-bough...\n",
      "\n",
      "[3] chili mock carne\n",
      "    Score: 0.1019\n",
      "    Cooking Time: 60 min | Ingredients: 16 | Steps: 9\n",
      "    Description: yes, it's a vegetarian chili con carne using tvp instead of beef. i actually served it up to my family and my dad and brother didn't really seem to no...\n",
      "\n",
      "[4] sara s veggie stromboli from scratch  using your bread machine\n",
      "    Score: 0.0958\n",
      "    Cooking Time: 40 min | Ingredients: 18 | Steps: 15\n",
      "    Description: with a picture! an easy, healthy, tasty vegetarian filled bread roll that has tangy italian flavors and makes a great meal all by itself! your kids wi...\n",
      "\n",
      "[5] extra cheesy crescent mozzarella wedges\n",
      "    Score: 0.0954\n",
      "    Cooking Time: 22 min | Ingredients: 4 | Steps: 7\n",
      "    Description: i was sitting here trying to figure out what would be a quick thing to feed my kiddos for lunch and at the same time thumbing through the most recent ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80df7c803b9c4400bd1e78977747080b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EMBEDDINGS RESULTS FOR: 'easy meal for kids'\n",
      "======================================================================\n",
      "\n",
      "[1] beef  rice  peas and carrots one dish meal\n",
      "    Similarity Score: 0.5787\n",
      "    Cooking Time: 20 min | Ingredients: 5 | Steps: 7\n",
      "    Tags: 30-minutes-or-less, time-to-make, course, preparation, healthy, 5-ingredients-or-less, main-dish, ea...\n",
      "    Description: quick, simple supper.  my 3 year old ate 6 servings, so i guess its kid friendly too. :)  i used a very lean beef that didn't require draining, if you...\n",
      "\n",
      "[2] sophie s super easy chickie pea and mato salad\n",
      "    Similarity Score: 0.5478\n",
      "    Cooking Time: 15 min | Ingredients: 12 | Steps: 4\n",
      "    Tags: 15-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, low-protein, health...\n",
      "    Description: a refreshing, flavorful salad with just a hint of smokiness.  my 3 year old and i were looking to make a quick and healthy lunch with what we had on h...\n",
      "\n",
      "[3] chicken nuggets parmesan\n",
      "    Similarity Score: 0.5409\n",
      "    Cooking Time: 10 min | Ingredients: 4 | Steps: 4\n",
      "    Tags: 15-minutes-or-less, time-to-make, course, main-ingredient, cuisine, preparation, occasion, north-ame...\n",
      "    Description: just like chicken parmesan but using chicken nuggets!  very kid friendly meal!  got recipe from a school cookbook!...\n",
      "\n",
      "[4] please don t feed the animals\n",
      "    Similarity Score: 0.5344\n",
      "    Cooking Time: 5 min | Ingredients: 4 | Steps: 3\n",
      "    Tags: 15-minutes-or-less, time-to-make, course, preparation, 5-ingredients-or-less, lunch, snacks, easy, k...\n",
      "    Description: i bought a small cookbooklet at the dollar general, and this recipe was in there. this sounds like a great munchie snack for the kids....\n",
      "\n",
      "[5] super easy chicken and noodles\n",
      "    Similarity Score: 0.5270\n",
      "    Cooking Time: 10 min | Ingredients: 6 | Steps: 2\n",
      "    Tags: 15-minutes-or-less, time-to-make, course, main-ingredient, preparation, main-dish, poultry, easy, ki...\n",
      "    Description: i'm not sure where this came from, but my kids really enjoyed this one!...\n"
     ]
    }
   ],
   "source": [
    "query = \"easy meal for kids\"\n",
    "\n",
    "# TF-IDF Results\n",
    "tfidf_results = tfidf_engine.search(query, top_k=5)\n",
    "display_search_results(tfidf_results, metadata_df, corpus_df, query, show_snippet=False)\n",
    "\n",
    "# Embeddings Results\n",
    "embed_results = embeddings_engine.search(query, top_k=5)\n",
    "display_search_results_embeddings(embed_results, metadata_df, corpus_df, query, engine_name=\"EMBEDDINGS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
